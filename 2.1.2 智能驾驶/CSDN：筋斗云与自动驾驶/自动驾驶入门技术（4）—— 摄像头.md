- [自动驾驶入门技术（4）—— 摄像头](https://blog.csdn.net/ckc108727ckc/article/details/107238450)

## 1、车载摄像头基础解析

### 1.1 工作原理

目标物体通过镜头（LENS）生成光学图像投射到图像传感器上，光信号转变为电信号，再经过A/D（模数转换）后变为数字图像信号，最后送到DSP（数字信号处理芯片）中进行加工处理，由DSP将信号处理成特定格式的图像传输到显示屏上进行显示。

### 1.2 摄像头主要硬件组件

1）镜头组（lens）- 镜头组由光学镜片、滤光片和保护膜等组成；

2） 图像传感器 - CMOS感光元件

MOS图像传感器（CIS）是模拟电路和数字电路的集成。主要有四个组件构成：微透镜、彩色滤光片（CF）、光电二极管（PD）、像素设计；

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213232527.png)

图1. CIS结构和CIS成像原理

3） DSP（数字信号处理芯片）

注：镜头组、CMOS芯片和胶合材料等组装成模组

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213321317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NrYzEwODcyN2NrYw==,size_16,color_FFFFFF,t_70)

图2. 摄像头硬件构成

### 1.3 基本工作流程

工作流程： 图像输入 — 预处理 — 特征提取 — 特征分类 — 匹配 — 完成识别

即输入摄像头的数据，以每帧信息为基础进行检测、分类、分割等计算，最后利用多帧信息进行目标跟踪，输出相关结果；

1）预处理包括成帧、颜色调整、白平衡、对比度均衡、图像扭正等工作；

2）特征提取在预处理的基础上提取出图像中的特征点；

3）目标识别是基于特征数据的输出，对图像中的物体进行识别分类 —— 人 ，车 、交通标志等，运用到机器学习、神经网络等算法。

### 1.4 车载摄像头类别

1.4.1 按摄像头的安装位置不同，可分为前视、侧视、后视和内置四个部分

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213402960.png)

1.4.2 车载摄像头按功能应用可分为行车辅助类、驻车辅助类与车内人驾驶员监控三大部分

1）行车辅助类：行车记录仪、车道偏离预警、开门预警， 盲区监测及交通标示识别等

a、智能前视（单目/双目/三目）：动态物体检测（车辆、行人）、静态物体检测（交通信号灯、交通标志、车道线等）和 可通行空间划分等。

b、侧视辅助（广角）：用于行车过程中监测后视镜盲区内的动态目标；

c、夜视辅助（夜视摄像头）：用于夜间或其他光线较差的情况下更好的实现目标物体的检测；根据工作原理的不同，目前夜视系统主要分三类：微光夜视技术、被动热成像夜视技术、主动红外夜视技术。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213419945.png)

图3. 行车辅助类摄像头

2）驻车辅助类：倒车影像/360环视

360环视（广角/鱼眼）：主要用于低速近距离感知；系统同时采集车辆四周的影像，经过图像处理单元畸变还原→视角转化→图像拼接→图像增强，最终形成一幅车辆四周无缝隙的 360 度全景俯视图。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213446961.png)

图4. 360环视系统框架及图象输出效果示意图

3）车内驾驶员监控（疲劳检测）

a、驾驶员监控系统功能定义：

主要针对驾驶员的疲劳、分神、不规范驾驶等危险情况进行一层或多层预警，要求在全部工况环境下（包含暗光、夜晚、逆光等）工作，且不受驾驶员衣着影响；

b、功能算法

DMS的视觉算法基于深度学习，以伟世通旗下的AllGoEmbedded系统为例，其DMS的基本流程如下：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213526742.png)

图5. 驾驶员疲劳检测

脸部检测：将其归为物体识别与分类问题，通过训练深度神经网络设计一个鲁棒性好的脸部检测器。

头部特征：由三个姿态角构成，基于CNN设计头部跟踪系统，以图像中脸部区域为输入，以三维姿态角为输出。

眼神检测：综合眼神检测网络与头部姿态角度输出。

眨眼检测：包括眨眼信息（速率与时差）和眼部信息（开与合)。眼部信息为二分类问题，需要神经网络较小；眨眼信息需要分析过去数帧。

## 2、单目与双目测距原理对比

### 2.1 单目摄像头

1）单目摄像头工作流程同样遵循图像输入、预处理、特征提取、特征分类、匹配、完成识别几个步骤，其测距原理是先匹配识别后估算距离：通过图像匹配识别出目标类别，随后根据图像大小估算距离；

2）单目测距的算法包括传统机器学习算法和深度学习中的卷积神经网络（CNN）算法；

a、传统算法

传统机器学习算法中，通过图像特征描述子SIFT、SURF、BRIEF进行特征点提取和匹配，可用特征很多，包括角点、边缘点、暗区的亮点及亮区的暗点等；

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213600674.png)

图6. 传统算法工作流程示意简图

b、深度学习算法

CNN主要针对图像处理，基本原理是通过多层过滤得到越来越抽象的图像特征，每个滤波器（由卷积核组成）学习并进行特征值提取，无需人工设计参数提取特征；

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213618617.png)

图7. 深度学习算法工作流程示意简图
两种算法的本质区别在于手动提取特征与机器学习特征，因此相比较而言，传统算法提取效率更低，鲁棒性不及深度学习算法；

### 2.2 双目摄像头

双目摄像头测距原理与人眼类似，通过对图像视差进行计算，直接对前方景物进行距离测量；从视差的大小倒推出物体的距离，视差越大，距离越近；

双目测距步骤：相机标定 —— 双目校正 —— 双目匹配 —— 计算深度信息（测距）

1）相机标定

摄像头由于光学透镜的特性使得成像存在着径向畸变；由于装配方面的误差，传感器与光学镜头之间并非完全平行，因此成像存在切向畸变；双目摄像头的定标不仅要得出每个摄像头的内部参数，还需要通过标定来测量两个摄像头之间的相对位置（即右摄像头相对于左摄像头的旋转矩阵R、平移向量t）。
2）双目校正

双目校正是根据摄像头定标后获得的单目内参数据（焦距、成像原点、畸变系数）和双目相对位置关系（旋转矩阵和平移向量），分别对左右视图进行消除畸变和行对准，使得左右视图的成像原点坐标一致、两摄像头光轴平行、左右成像平面共面、对极线行对齐。

3）双目匹配

双目匹配的作用是把同一场景在左右视图上对应的像点匹配起来，这样做的目的是为了得到视差图。双目匹配被普遍认为是立体视觉中最困难也是最关键的问题。

4）计算深度信息

如下图所示，P是待测物体上的某一点，OR与OT分别是两个相机的光心，点P在两个相机感光器上的成像点分别为P和P’（相机的成像平面经过旋转后放在了镜头前方），f为相机焦距，B为两相机中心距，Z为深度信息，设点P到点P’的距离为dis，则：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213724477.png)

根据相似三角形原理：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213713845.png)

可得：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213733736.png)

（公式中，焦距f和摄像头中心距B可通过标定得到，因此只要获得XR-XT（即视差d）的值即可求得深度信息；）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213743882.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NrYzEwODcyN2NrYw==,size_16,color_FFFFFF,t_70)

图8. 双目测距原理示意图

### 2.3 单/双目方案的优劣势分析

1）单目摄像机

优势：成本较低，对计算资源的要求不高，系统结构相对简单；

劣势/难点：（1）需要不断更新和维护一个庞大的样本数据库，才能保证系统达到较高的识别率；（2）无法对非标准障碍物进行判断；（3）距离并非真正意义上的测量，准确度较低。

2）双目摄像机

优势：（1）没有识别率的限制，因为从原理上无需先进行识别再进行测算；（2）直接利用视差计算距离，精度比单目高；（3）无需维护样本数据库，因为对于双目没有样本的概念。

劣势/难点：（1）计算量非常大，对计算单元的性能要求非常高，这使得双目系统的产品化、小型化的难度较大。（2）双目视觉系统通过估计视差来测距，而视差是通过立体匹配算法得来的，立体匹配是计算机视觉典型的难题；（3）双目在线标定比单目要更复杂些，因为双目匹配需尽量简化成1-D搜索，所以需要通过stereo rectification将两个镜头光轴方向平行并和基线垂直。

## 3 、车规级摄像头性能要求

1、耐高温 ：车载摄像头需在-40℃~85℃范围内都能正常工作，且能适应温度的剧烈变化；

2、抗震：车辆在不太平坦的路面行驶会产生较强的震动，因此车载摄像头必须能抗各种强度的震动；

3、防磁 ： 车辆启动时会产生极高的电磁脉冲，需要极高的防磁性能；

4、防水 ： 载摄像头密封要非常严实，满足在雨水中浸泡数日仍可正常使用；

5、使用寿命 ： 使用寿命至少为8~10年才能满足要求；

6、超广角： 侧视环视摄像头必须是超广角的，水平视角达 135°；

7、高动态： 车辆行驶速度快，摄像头面对的光线环境变化剧烈且频繁，要求摄像头的CMOS 具有高动态特性；

8、低噪点： 在光线较暗时能有效抑制噪点，特别是要求侧视和后视摄像头即使在晚上也能清楚的捕捉影像。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200709213831592.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NrYzEwODcyN2NrYw==,size_16,color_FFFFFF,t_70)

图9. 车载摄像头工艺流程

## 4、车载摄像头的内外参标定

机标定的目标就是为了获得相机的内参数和相机的外参数；

### 4.1 内参标定

1）内参矩阵（Sx,Sy,Cx,Cy,f）：代表相机的内部结构参数

参数说明：Sx和Sy代表相机芯片单个像素的物理尺寸Sx = 1/dx, Sy =  1/dy，单位是像素/毫米，一般情况下Sx=Sy，除非单个像素点在成像仪上是矩形而不是正方形。  Cx和Cy分别代表相机芯片的中心可能的偏移，这是因为芯片的安装通常无法绝对精准。 f代表相机的焦距，fx = f * Sx，fy=f * Sy。

 2）畸变参数：k1,k2,k3径向畸变系数，p1,p2是切向畸变系数。（五个畸变参数，一般只需计算出k1,k2，p1,p2；对于鱼眼摄像头等径向畸变特别大的才需要计算出k3。）径向畸变发生在相机坐标系转图像物理坐标系的过程中；而切向畸变是发生在相机制作过程，其是由于感光元平面跟透镜不平行。

a、径向畸变：产生原因是光线在远离透镜中心的地方比靠近中心的地方更加弯曲，径向畸变主要包含桶形畸变和枕形畸变两种。

b、切向畸变：产生的原因透镜不完全平行于图像平面，这种现象发生于成像仪被粘贴在摄像机的时候。

3）内参的标定方式主要可以归为三类：传统的标定方法、基于主动视觉的标点以及自标定；目前常用的标定方法还是传统标定方法，比如张氏标定。

### 4.2 外参标定

相机外参数是相机的旋转矩阵R和平移向量t；旋转矩阵和平移矩阵共同描述了如何把点从世界坐标系转换到摄像机坐标系；

1）旋转矩阵：描述世界坐标系->相机坐标系的旋转变换

2）平移矩阵：描述世界坐标系->相机坐标系的平移变换

世界坐标系（world coordinate），也称为测量坐标系，是一个三维直角坐标系，以其为基准可以描述相机和待测物体的空间位置。世界坐标系的位置可以根据实际情况自由确定。

相机坐标系（camera coordinate），也是一个三维直角坐标系，原点位于镜头光心处，x、y轴分别与相面的两边平行，z轴为镜头光轴，与像平面垂直。

## 5、感知模块中摄像机的技术特点解析

### 5 .1 优势分析

1）相比于毫米波雷达，目前摄像头的主要优势在于：

a、目标识别与分类 - 目前普通的3D毫米波雷达仅可以检测到前方是否有障碍物，而无法精准识别障碍物的大小和类别；例如：各类车道线识别、红绿灯识别以及交通标志识别等；

b、可通行空间检测（FreeSpace） - 对车辆行驶的安全边界（可行驶区域）进行划分，主要对车辆、普通路边沿、侧石边沿、没有障碍物可见的边界、未知边界进行划分；

c、对横向移动目标的探测能力 ，比如对十字路口横穿的行人以及车辆的探测和追踪；

d、定位与地图创建 - 即视觉SLAM技术，虽然目前也有用毫米波雷达做SLAM的，不过视觉SLAM技术更加成熟，也更有应用前景；

2）在自动驾驶系统中，激光雷达与摄像头感知作用比较类似，但相比激光雷达，其优势为：

a、红绿灯识别及交通标示识别

b、成本优势，且算法及技术成熟度比较高

c、物体识别率高

### 5.2 劣势分析

1）受天气、光照变化影响大，极端恶劣天气下视觉传感器会失效；

2）测距/测速性能不如激光雷达和毫米波雷达；

## 6、车载智能前视像头（单目/双目）关键参数

1）探测距离

2）水平视场角

3）垂直视场角

4）分辨率

当摄像机摄取等间隔排列的黑白相间条纹时，在监视器（比摄像机的分辨率要高）上能够看到的最多线数，当超过这一线数时，屏幕上就只能看到灰蒙蒙的一片，

而不再能分辨出黑白相间的线条。

5）最低照度

最低照度，即图像传感器对环境光线的敏感程度，或者说是图像传感器正常成像时所需要的最暗光线。它是当被摄物体的光照逐渐降低时，摄像机的视频信号电平

低于标准信号最大幅值一半时的景物光照度值。

6）信噪比

输出信号电压与同时输出的噪声电压的比值；

7）动态范围

摄像机拍摄的同一个画面内，能正常显示细节的最亮和最暗物体的亮度值所包含的那个区间。动态范围越大，过亮或过暗的物体在同一个画面中都能正常显示的程度也就越大。