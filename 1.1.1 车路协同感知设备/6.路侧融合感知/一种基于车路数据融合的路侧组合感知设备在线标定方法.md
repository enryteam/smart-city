- [一种基于车路数据融合的路侧组合感知设备在线标定方法](http://www.doc88.com/p-77347197245738.html)

本发明涉及一种基于车路数据融合的路侧组合感知设备在线标定方法,所述的路侧感知设备包括分别安装于路侧的视频摄像头和毫米波雷达,该方法包括以下步骤:

S1:路侧感知设备采集道路车辆数据,并获取第类车辆的实时位置数据；

S2：基于第一类车辆的实时位置数据，对视频摄像头检测目标的坐标进行标定;

S3:利用完成标定的视频摄像头,对毫米波雷达检测目标的坐标进行标定;

S4：利用完成标定的视频摄像头和毫米波雷达,在不同时刻对第二类车辆进行坐标定位,与现有技术相比,本发明具有降低人力和定位装置成本、操作简单等优点。

![image-20220209145626472](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209145626472.png)

1.一种基于车路数据融合的路侧组合感知设备在线标定方法,其特征在于,所述的路侧组合感知设备有多个路侧感知设备(1)组合而成,所述的路侧感知设备(1)包括分别安装于路侧的视频摄像头(11)和毫米波雷达(12),该方法包括以下步骤：

S1：路侧感知设备(1)采集道路车辆数据，并获取第一类车辆(41)的实时位置数据，所述的第一类车辆(41)能够联网并提供自身定位数据；

S2:基于第一类车辆(41)的实时位置数据,对视频摄像头(11)检测目标的坐标进行标定,建立视频图像像素坐标系与世界坐标系的映射关系；

S3:利用完成标定的视频摄像头(11),对毫米波雷达(12)检测目标的坐标进行标定,得到毫米波雷达(12)检测目标坐标系与视频图像像素坐标系之间的映射关系；

S4：利用完成标定的视频摄像头(11)和毫米波雷达(12),在不同时刻对第二类车辆(42)进行坐标定位。

2.根据权利要求1所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,所述的第一类车辆(41)为配备有定位设备的网联车辆,所述的第二类车辆(42)为除去第一类车辆(41)后剩下的车辆。

3.根据权利要求1所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S1具体包括：

S11:对视频摄像头(11)和毫米波雷达(12)进行布设,并分别接入中心服务器(3)进行时钟同步；

S12：路侧感知设备(1)按照设定采样频率采集道路车辆数据,得到目标检测数据；

S13：根据路侧感知设备(1)的姿态变化周期,获取对应数量第一类车辆(41)的实时位置数据。

4.根据权利要求3所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S13具体为：

当路侧感知设备(1)的姿态变化周期大于2秒时,至少分两次获取两辆第一类车辆(41)的实时位置数据；

当路侧感知设备(1)的姿态变化周期小于2秒时,至少一次性获取四辆第类车辆(41)的实时位置数据。

5.根据权利要求3所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S11中,对视频摄像头(11)和毫米波雷达(12)进行布设具体为:将视频摄像头(11)与毫米波雷达(12)布设于路侧立杆(2)同一位置,两者经纬度坐标保持一致,且向下倾斜俯角均为10°。

6.根据权利要求1所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S2具体包括：

S21:利用训练完成的车辆目标检测算法,框选出视频摄像头(11)拍摄图像中的所有车辆；

S22：将框选出的车辆信息与第一类车辆(41)的信息进行匹配；

S23:获取匹配成功的第一类车辆(41)在视频图像像素坐标系下的坐标和对应的实时位置数据,将实时位置数据作为第一类车辆(41)在世界坐标系下的坐标；

S24：通过计算视频图像像素坐标系与世界坐标系的单应性变换矩阵,获取两坐标系之间的映射关系,完成视频摄像头(11)检测目标的坐标标定。

7.根据权利要求6所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S21中,利用训练完成的车辆目标检组合测算法,获取每一车辆的图像特征和位置特征,所述的图像特征包括车辆的颜色、形状、和车牌号,所述的位置特征包括目标车辆的区域框；

步骤S22中,通过获取的图像特征和位置特征,与第一类车辆(41)联网上传的信息,进行信息匹配。

8.根据权利要求1所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S3使用全局最优匹配算法,建立优化模型,使用启发式算法求解其参数，得到毫米波雷达(12)检测目标坐标系与视频图像像素坐标系之间的映射关系。

9.根据权利要求8所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S3具体包括：

S31：选取视频目标检测矩形框底边中点像素坐标作为对应车辆的像素坐标,根据已标定好的像素坐标系与世界坐标系之间的映射关系,得到视频图像内所有目标检测车辆的世界坐标；

S32：基于毫米波雷达(12)采集数据,得到毫米波雷达(12)视野范围内的目标检测结果,并根据毫米波雷达(12)在世界坐标系下的坐标,计算毫米波雷达(12)检测目标在世界坐标系下的坐标；

S33:基于全局最优匹配算法,对视频摄像头(11)与毫米波雷达(12)计算的检测目标的世界坐标进行匹配,得到毫米波雷达(12)检测目标坐标系与视频图像像素坐标系之间的映射关系,完成雷达检测目标的坐标标定。

10.根据权利要求1所述的一种基于车路数据融合的路侧组合感知设备在线标定方法，其特征在于,步骤S4具体包括:利用已经完成标定的视频摄像机和毫米波雷达(12),对第二类车辆(42)进行定位,获取其准确的图像、速度和航向角信息,且当路侧感知设备(1)产生振动偏移或旋转时,重复步骤S1至步骤S4。

## 技术领域

[0001]本发明涉及移动车辆检测和传感器检测目标坐标标定技术领域，尤其是涉及一种基于车路数据融合的路侧组合感知设备在线标定方法。

## 背景技术

[0002]传感器检测目标坐标标定是车路协同和自动驾驶的基本需求。为了及时准确地感知周围环境的多源信息,车辆与路侧往往会安装多个传感器(如视频摄像头、毫米波雷达)。每个传感器在测量时将世界坐标系下的检测目标坐标映射至自身对应的相对坐标系,但由于各个传感器的安装位置、姿态和角度不同,其坐标映射关系也有所差异。传感器的坐标标定是指,通过一定的技术手段或方法,建立设备自身相对坐标系与世界坐标系之间的映射关系,实现不同传感器捕捉到的同一目标坐标映射在世界坐标系中保持为同一坐标或坐标误差在精度要求范围内。

[0003]基于雷视融合的毫米波雷达标定方法往往需要先对摄像头进行内外参数标定,再由视频图像对雷达进行标定。传统的摄像头标定方法主要采用人工标定的方法,将标定棋盘图铺设在视频摄像头视野范围内的路面上,采用张正友标定法和RTK差分定位技术标定视频摄像头内部参数与外部参数,通过建立视频图像像素坐标与世界经纬度坐标的映射关系,实现对摄像头内外参数的标定。该方法应用广泛但缺点也十分明显:标定方法过于依赖人工,仅适用于小范围内的标定,难以大规模的批量应用。并且在实际的复杂交通环境中，传感器因强风、桥振等外部因素发生振动偏移,或因人为的旋转产生姿态的变化,导致之前建立的坐标系映射关系失效,此时传感器的参数就需要重新标定。

[0004]近年来,随着人工智能算法和深度神经网络在机器视觉领域的不断发展,基于深度学习和目标检测技术的传感器自标定方法被提出,该方法可以解决传统标定方法依赖于人工的问题,并且能够实时解决传感器重新标定的难题,但该方法由于需要在路侧安装大量静态标志物,成本昂贵,不适宜大范围推广。为此,亟需一种实用性强的方法解决多源传感器检测目标坐标在线标定的问题。

## 发明内容

[0005]本发明的目的就是为了克服上述现有技术存在的缺陷而提供一种降低人力和定位装置成本、操作简单的基于车路数据融合的路侧组合感知设备在线标定方法。[0006]本发明的目的可以通过以下技术方案来实现：

[0007]一种基于车路数据融合的路侧组合感知设备在线标定方法,其特征在于,所述的路侧组合感知设备有多个路侧感知设备组合而成,所述的路侧感知设备包括分别安装于路侧的视频摄像头和毫米波雷达,该方法包括以下步骤：

[0008]S1:路侧感知设备采集道路车辆数据,并获取第一类车辆的实时位置数据,所述的第一类车辆能够联网并提供自身定位数据；

[0009]S2:基于第一类车辆的实时位置数据,对视频摄像头检测目标的坐标进行标定,建立视频图像像素坐标系与世界坐标系的映射关系；

[0010]S3：利用完成标定的视频摄像头，对毫米波雷达检测目标的坐标进行标定,得到毫米波雷达检测目标坐标系与视频图像像素坐标系之间的映射关系；

[0011]S4：利用完成标定的视频摄像头和毫米波雷达,在不同时刻对第二类车辆进行坐标定位。

[0012]进一步地,所述的第一类车辆为配备有定位设备的网联车辆,所述的第二类车辆为除去第一类车辆后剩下的车辆，配备定位设备的第一类车辆配备可以采用带有RTK差分定位技术的网联车辆,且均在道路上以不低于20km/h的速度行驶。

[0013]进一步地,步骤S1具体包括：

[0014]S11:对视频摄像头和毫米波雷达进行布设,并分别接入中心服务器进行时钟同步；

[0015]S12：路侧感知设备按照设定采样频率采集道路车辆数据,得到目标检测数据；

[0016]S13：根据路侧感知设备的姿态变化周期,获取对应数量第一类车辆的实时位置数据。

[0017]更进一步地,步骤S13具体为：

[0018]当路侧感知设备的姿态变化周期大于2秒时，至少分两次获取两辆第一类车辆的实时位置数据；当路侧感知设备的姿态变化周期小于2秒时，至少一次性获取四辆第一类车辆的实时位置数据。

[0019]更进一步地,步骤S11中,对视频摄像头和毫米波雷达进行布设具体为:将视频摄像头与毫米波雷达布设于路侧立杆同一位置,两者经纬度坐标保持一致,且向下倾斜俯角均为10°。

[0020]进一步地,步骤S2具体包括：[0021]S21:利用训练完成的车辆目标检测算法,框选出视频摄像头拍摄图像中的所有车辆；

[0021]S21：利用训练完成的车辆目标检算法,框选出视频摄像头拍摄图像中的所有车辆；[0022]S22：将框选出的车辆信息与第一类车辆的信息进行匹配；

[0023]S23：获取匹配成功的第一类车辆在视频图像像素坐标系下的坐标和对应的实时位置数据,将实时位置数据作为第一类车辆在世界坐标系下的坐标；

[0024]S24：通过计算视频图像像素坐标系与世界坐标系的单应性变换矩阵,获取两坐标系之间的映射关系,完成视频摄像头检测目标的坐标标定。

[0025]更进一步地,步骤S21中,利用训练完成的车辆目标检测算法,获取每一车辆的图像特征和位置特征,所述的图像特征包括车辆的颜色、形状、和车牌号,所述的位置特征包括目标车辆的区域框；

[0026]步骤S22中,通过获取的图像特征和位置特征,与第一类车辆联网上传的信息,进行信息匹配。

[0027]进一步地,步骤S3使用全局最优匹配算法,建立优化模型,使用启发式算法求解其参数,得到毫米波雷达检测目标坐标系与视频图像像素坐标系之间的映射关系。

[0028]更进一步地,步骤S3具体包括：

[0029]S31：选取视频目标检测矩形框底边中点像素坐标作为对应车辆的像素坐标,根据已标定好的像素坐标系与世界坐标系之间的映射关系,得到视频图像内所有目标检测车辆的世界坐标；

[0030]S32：基于毫米波雷达采集数据,得到毫米波雷达视野范围内的目标检测结果,并根据毫米波雷达在世界坐标系下的坐标,计算毫米波雷达检测目标在世界坐标系下的坐标；

[0031]S33：基于全局最优匹配算法,对视频摄像头与毫米波雷达计算的检测目标的世界坐标进行匹配,得到毫米波雷达检测目标坐标系与视频图像像素坐标系之间的映射关系，完成雷达检测目标的坐标标定。

[0032].进一步地，步骤S4具体包括：利用已经完成标定的视频摄像机和毫米波雷达，对第二类车辆进行定位,获取其准确的图像、速度和航向角信息,且当路侧感知设备产生振动偏移或旋转时，重复步骤S1至步骤S4。

[0033]与现有技术相比,本发明具有以下优点：

[0034]本发明方法运用带有高精度定位设备的网联车辆的车路融合数据对路侧摄像头及毫米波雷达感知设备检测目标坐标进行实时在线标定,车载定位装置可达到厘米级的定位精度，且能够实时向云端发送自身位置信息,将其作为路侧视频和雷达感知设备的标定数据来源,可以大大降低标定所需人工和定位装置的成本和难度,有效解决多源感知设备检测目标坐标在线标定的难题。

## 附图说明

[0035]图1为本发明方法的流程示意图；

[0036]图2为本发明路侧感知设备的布设图；

[0037]图3为实施例中数据采集步骤的示意图；

[0038]图4为实施例中视频摄像头标定步骤的示意图；

[0039]图5为实施例中雷达标定步骤的示意图。

[0040]其中,1、路侧感知设备,11、视频摄像头,12、毫米波雷达,2、路侧立杆,3、中心服务器,41、第一类车辆,42、第二类车辆。

## 具体实施方式

[0041]下面结合附图和具体实施例对本发明进行详细说明。显然,所描述的实施例是本发明的一部分实施例，而不是全部实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动的前提下所获得的所有其他实施例,都应属于本发明保护的范围。

[0042]实施例

[0043]本发明公开了一种基于车路数据融合的路侧组合感知设备在线标定方法,所述的路侧感知设备1包括分别安装于路侧的视频摄像头11和毫米波雷达12,该方法包括以下步骤：

[0044]S1:路侧感知设备1采集道路车辆数据,并获取第一类车辆41的实时位置数据,所述的第一类车辆41能够联网并提供自身定位数据,具体指配备有高精定位设备的网联车辆,本实施例中采用带有RTK差分定位技术,且在道路上以不低于20km/h的速度行驶的网联车辆，另外,第二类车辆42为除去第一类车辆41后剩下的车辆,主要指未配备有高精定位设备或非联网的车辆。

[0045]步骤S1具体过程包括：

[0046]路侧感知设备1布设与时钟同步：本实施例中,将视频摄像头11与毫米波雷达12布设于路侧立杆2同一位置,使得两者经纬度坐标保持一致,且向下倾斜俯角约为10°,同时将视频摄像头11与毫米波雷达12均接入中心服务器3,进行统一授时,对视频摄像头11与毫米波雷达12数据进行时间校准,使视频数据与毫米波雷达12数据达到时钟同步；

[0047]数据采集：视频摄像头11与毫米波雷达12不间断采集道路检测目标数据。同时，网联车辆的数量根据感知设备姿态变化的周期的快慢而有不同的要求：

[0048] (1)当感知设备姿态变化周期大于2秒时(如人为控制摄像头旋转),使用不少于2辆带有RTK差分定位技术的网联实验车辆进行数据采集，具体为：至少分两次采集2辆实验车辆实时世界经纬度坐标,即至少同一视野范围内4个点的坐标；

[0049] (2)当感知设备姿态变化周期小于2秒时(如强风或桥振引起的振动),使用不少于4辆带有RTK差分定位技术的网联实验车辆进行数据采集，具体为：以1帧为数据上传频率，在该时间间隔中至少一次性采集4辆实验车辆实时世界经纬度坐标。

[0050]S2:基于第一类车辆41的实时位置数据,对视频摄像头检测目标的坐标进行标定，建立视频图像像素坐标系与世界坐标系的映射关系,具体为:利用深度学习目标检测算法对车辆目标进行检测，并计算像素坐标系与世界坐标系之间的单应性变换矩阵，建立图像坐标系与世界坐标系的映射关系,具体过程如下：

[0051] (1)使用预训练得到的深度学习车辆目标检测算法,框选出视频摄像头11所拍摄图像中的所有车辆；

[0052] (2)将图像中所框选出的车辆信息与接收到的网联车辆信息进行匹配,获取不同网联车辆在视频摄像头11的像素坐标系下的坐标与真实世界坐标系下的坐标；

[0053] (3)通过计算像素坐标系与世界坐标系的单应性变换矩阵获取两坐标系之间的映射关系,即完成视频摄像头11检测目标的坐标标定。

[0054]S3：利用完成标定的视频摄像头11,对毫米波雷达12检测目标的坐标进行标定,得到毫米波雷达12检测目标坐标系与视频图像像素坐标系之间的映射关系,具体为:使用全局最优的匹配算法,建立优化模型,使用启发式算法求解其参数,得到毫米波雷达12检测目标坐标与视频图像像素坐标之间的映射关系,具体过程如下：

[0055] (1)选取视频目标检测矩形框底边中点像素坐标作为该车辆的像素坐标,根据已标定好的像素坐标系与世界坐标系之间的映射关系,计算视频图像内所有检测目标车辆的世界坐标； 

[0056] (2)基于毫米波雷达12设备数据,得到毫米波雷达12视野范围内的目标检测结果，即目标在毫米波雷达12相对坐标系的坐标。根据毫米波雷达12所在路侧立杆2的世界坐标，计算毫米波雷达12检测目标的世界坐标； 

[0057] (3)基于全局最优的匹配算法,对视频与毫米波雷达12计算的检测目标的世界坐标进行匹配,得到毫米波雷达12检测目标坐标与视频图像像素坐标之间的映射关系,即完成雷达检测目标的坐标标定。

[0058]S4:利用完成标定的视频摄像头11和毫米波雷达12,在不同时刻对第二类车辆42进行坐标定位，具体为,利用已经完成标定的视频摄像机和毫米波雷达12,对未配备高精度定位设备的车辆进行定位,获取其准确的图像、速度、航向角等信息,若感知设备产生振动偏移或旋转,重复步骤S1至步骤S4。

[0059]如图1所示,本实施例中,在线标定的具体过程分为五个步骤,如下：

[0060]第一步：传感器布设与时钟同步

[0061]依靠视频摄像头11与毫米波雷达12两种传感器数据实现多车辆目标检测。如图2所示,视频摄像头11应与毫米波雷达12布设于路侧立杆2同一位置,使得两者经纬度坐标保持一致,传感器向下倾斜俯角约为10°两类传感器均接入中心服务器3,进行统一授时。

[0062]第二步：数据采集

[0063]如图3所示,路侧感知设备1(包括视频摄像头11和雷达)以25Hz的采样频率采集道路车辆数据信息。同时,使用联网的实验车辆安装车载RTK,获取实验联网车辆实时世界经纬度度坐标，并根据感知设备姿态变化的周期的快慢,使用不同数量的实验网联车辆采集数据：

[0064] (1)感知设备姿态变化周期大于2秒

[0065]经历人工旋转或移动时,路侧感知设备1姿态变化周期往往大于2秒,在该时间段内完成路侧感知设备1的常规校准,至少分两次采集2辆实验车辆实时世界经纬度坐标,即至少同一视野范围内4个点的坐标。 

[0066] (2)感知设备姿态变化周期小于2秒

[0067]经历大风天气、桥面自振时,路侧感知设备1往往在极短时间内发生高频的振动偏移,实时在线标定需要在短时间内完成路侧感知设备1的快速校准。以1帧为数据上传频率，在该时间间隔中至少一次性采集4辆实验车辆实时世界经纬度坐标。

[0068]第三步：视频摄像头11在线标定

[0069]如图4所示,利用所采集的视频摄像头11信息和实验网联车辆的信息,使用预训练后的深度学习目标检测算法对摄像头视野范围内的多辆实验网联车辆进行目标识别,并获取出每一个实验车辆的图像特征和位置特征。其中图像特征包括车辆的颜色、形状、车牌号等;位置特征主要指包含目标车辆的区域框。利用目标车辆的图像特征与位置特征,与不断上传信息的网联车辆在图像中一一匹配,得到每一辆网联实验车辆在图像坐标系的坐标和世界坐标系下的坐标。基于上述步骤获取的两类坐标,建立图像坐标系与世界坐标系的映射关系,通过计算得到单应性矩阵,完成视频摄像头11的在线标定。

[0070]第四步：雷达在线标定

[0071]雷达在线标定的示意图如图5所示：

[0072] (1)选取视频目标检测矩形框底边中点像素坐标作为该车辆的像素坐标,根据已标定好的像素坐标系与世界坐标系之间的映射关系,计算视频图像内所有检测目标车辆的世界坐标；  

[0073] (2)基于毫米波雷达12设备数据,得到毫米波雷达12视野范围内的目标检测结果，即目标在毫米波雷达12相对坐标系的坐标。根据毫米波雷达12所在立柱的世界坐标，计算毫米波雷达12检测目标的世界坐标；

[0074] (3)基于全局最优的匹配算法,对视频与毫米波雷达12计算的检测目标的世界坐标进行匹配,得到毫米波雷达12检测目标坐标与视频图像像素坐标之间的映射关系,即完成雷达检测目标的坐标标定。

[0075]第五步：非网联车辆定位

[0076]>将在线标定的结果上传云服务器保存。利用已经完成标定的路侧感知设备1(视频、雷达等),对未配备高精度定位设备的车辆进行定位,获取其准确的图像、速度、航向角等信息。若感知设备产生振动偏移或旋转,重复第一步至第四步。

[0077]以上所述,仅为本发明的具体实施方式,但本发明的保护范围并不局限于此,任何熟悉本技术领域的工作人员在本发明揭露的技术范围内,可轻易想到各种等效的修改或替换,这些修改或替换都应涵盖在本发明的保护范围之内。因此,本发明的保护范围应以权利要求的保护范围为准。

![image-20220209150644542](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209150644542.png)

![image-20220209150717433](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209150717433.png)

![image-20220209150753960](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209150753960.png)

![image-20220209150835465](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209150835465.png)

![image-20220209150910744](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209150910744.png)