- [一种基于深度学习的路侧视角超视距全域融合感知系统](https://cprs.patentstar.com.cn/Search/Detail?ANE=9AIB9IFE9GDC8FCA9IFF3CBABGHA7BCABDIA9BBC9DBCBEGA)

## 摘要

本发明涉及一种基于深度学习的路侧视角超视距全域融合感知系统 ，对路侧布置的摄像头、激光雷达、毫米波雷达异构数据采集和进行数据层融合，并利用深度学习分别处理融合后的图像和激光雷达点云数据，最终利用决策层融合实现融合感知。通过在路侧布置感知系统，并结合图像、激光雷达点云、毫米波雷达点云数据各自的优势，可以提升感知视距，并在多个层面对监控区域进行场景理解，最终为网联自动驾驶车辆提供充足可靠的感知信息。

1 .一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：包括以下步骤：
步骤1、在路侧布置传感器模组，包括摄像头、激光雷达、毫米波雷达；
步骤2、采集传感器数据，包括摄像头的图像数据、激光雷达的点云数据、毫米波雷达的点云数据并进行预处理，包括时间同步、噪声滤波、数据解析、数据拼接；
步骤3、将预处理后的传感器数据输入到数据层融合模块进行数据层融合处理；
步骤4、将数据层融合处理后的图像数据输入到图像语义分割模块，通过预先构建好的深度学习语义分割模型进行语义理解；将数据层融合处理后的激光雷达点云数据输入到激光雷达点云分割模块，通过预先构建好的点云级别的深度学习分割模型进行点云分割；
步骤5、将图像语义分割结果和激光雷达点云分割结果输入到决策层融合模块进行处理，得到最终的感知结果和路侧感知系统的输出信息。
2 .根据权利要求1所述的一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：步骤1中，摄像头、激光雷达、毫米波雷达布置在交叉路口或存在视野盲区的区域，摄像头布置时应使摄像头的采集范围覆盖整个待识别路段，激光雷达布置时应尽量使更多点云落在待识别路段上，毫米波雷达应覆盖每条单行车道的较远区域。
3 .根据权利要求1所述的一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：步骤3中，数据层融合模块对传感器数据的处理步骤如下：
步骤3 .1、以图像为基准，限制有效的识别范围；
步骤3 .2、将激光雷达点云数据投影到图像的成像平面上，对有效识别范围之外的激光雷达点云进行去除；
步骤3 .3、将毫米波雷达点云数据投影到图像的成像平面上，对有效识别范围之外的毫米波雷达点云进行去除；
步骤3 .4、根据图像、处理后的激光雷达点云、处理后的毫米波雷达点云构建数据层融合模型并输出数据；构建的数据层融合模型如下式所示：

![image-20220209151106506](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151106506.png)

![image-20220209151126891](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151126891.png)

![image-20220209151140667](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151140667.png)

6 .根据权利要求1所述的一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：步骤4中，对图像数据进行语义理解的处理步骤如下：
(1)对获得的数据层融合数据进行提取，得到用于图像语义分割的输入数据；
(2)对获得的用于图像语义分割的输入数据进行减均值预处理；
(3)利用构建好的图像语义分割深度学习模型进行前向推导运算，得到与输入图片同尺寸的像素级分割结果；
(4)对得到的分割结果进行形态学运算，得到图像语义分割模块的输出结果；

步骤4中，对激光雷达进行点云分割的处理步骤如下：
(1)对获得的数据层融合数据进行提取，得到用于激光雷达点云分割的输入数据；
(2)对获得激光雷达点云数据进行预处理，去除地面点云，并将非地面点云处理成固定个数；
(3)利用构建好的激光雷达点云分割深度学习模型对预处理后的激光雷达点云数据进行分割；
(4)对分割结果和激光雷达点云输入数据进行处理，得到激光雷达点云分割模块的输出结果。
7 .根据权利要求6所述的一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：对图像数据进行语义理解步骤(3)中所述的图像语义分割深度学习模型的构建方法如下：

首先，输入预先采集、标注好的训练集；其次，设计图像语义分割深度学习模型的网络结构和损失函数，并利用训练集进行训练；然后，输入预先采集、标注好的测试集进行测试；
最后，在实际场景中部署图像语义分割算法，并依据测试结果和实际部署效果判断是否达到预期效果，如果没有达到，则补充训练集重新训练；
对激光雷达进行点云分割步骤(3)中所述的激光雷达点云分割深度学习模型的构建方法如下：
首先，输入预先采集、标注好的训练集；其次，设计激光雷达点云分割深度学习模型的网络结构和损失函数，并利用训练集进行训练；然后，输入预先采集、标注好的测试集进行测试；最后，在实际场景中部署激光雷达点云分割算法，并依据测试结果和实际部署效果判断是否达到预期效果，如果没有达到，则补充训练集重新训练。
8 .根据权利要求1所述的一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：步骤5中，决策层融合模块对输入数据的处理步骤如下：
步骤5 .1、将图像语义分割模块的输出、激光雷达点云分割模块的输出、毫米波雷达点云数据输入到决策层融合模块；
步骤5 .2、将激光雷达点云分割模块的输出、毫米波雷达点云数据投影到图像成像空间；
步骤5 .3、利用图像语义分割结果构建决策层融合基准数据，基准数据模型如下：

![image-20220209151232048](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151232048.png)

步骤5 .7、对比图像融合数据优化前后结果差异，如果优化前后差异超过阈值，则对激光雷达融合数据、毫米波雷达融合数据进行调整，并重复步骤5 .4、5 .5、5 .6；如果优化前后差异未超过阈值，则保留优化后图像融合数据、激光雷达融合数据、毫米波雷达融合数据，并构建决策层融合模块输出数据。

9 .根据权利要求8所述的一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：步骤5 .3中，图像标签矩阵由下式生成：

![image-20220209151301184](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151301184.png)

10 .根据权利要求8所述的一种基于深度学习的路侧视角超视距全域融合感知系统，其特征在于：步骤5 .7中，图像融合数据差异计算模型如下所示：

![image-20220209151318677](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151318677.png)

步骤5 .7中，对激光雷达融合数据、毫米波雷达融合数据调整的方式为：利用优化后的图像标签对落在同一标签区域内的激光雷达点云、毫米波雷达点云标记为同一类别，并将新的标签替代原来的标签；决策层融合模块输出数据包含标签、位置、尺寸信息，实现感知系统对场景内目标的全域感知。

## 一种基于深度学习的路侧视角超视距全域融合感知系统

### 技术领域

[0001] 本发明涉及一种智能交通基础设施系统，特别涉及一种基于深度学习的路侧视角超视距全域融合感知系统。

### 背景技术

[0002] 智能交通基础设施的发展是实现车辆网联自动驾驶功能的关键，路侧感知系统作为车路协同感知系统中路侧感知信息的获取来源，其稳定性和可靠性将直接影响网联自动驾驶功能的实现和安全性。在智能交通技术和自动驾驶技术蓬勃发展的今日，路侧感知系统的稳定性和可靠性仍是急需解决的关键点。
[0003] 自动驾驶系统通常包括感知、决策、控制三个模块，其中感知是整个自动驾驶系统与周围环境交互的接口，其准确性直接影响自动驾驶功能的可实现性。现有感知方法主要集中在基于车载传感器实现，但是车载传感器受其安装位置限制，交通拥堵路况复杂时感知视角易受遮挡、视距较短，同时车载传感器价格较高。基于车载传感器的感知方法，从使用数据上看可以分为基于单一类型传感器数据和基于多传感器数据融合两种，其中基于多传感器融合的方法提升了感知算法可利用的数据维度，同时兼顾不同传感器各自的工作特点和数据优势。多传感器数据融合从一定程度上扩大了感知视距和优化了感知视角，但基于车载传感器的感知方法在视野、视角、价格等方面的局限性由于传感器布置位置首先无法完全克服，道路拥堵工况时常发生。
[0004] 近年来5G通信技术飞速发展，促进智能交通技术不断完善，同时使网联自动驾驶技术成为实现L5级完全自动驾驶功能的最佳方案之一。其中，路侧感知模块在传感器视野、视距方面具有巨大优势，受交通拥堵影响较小，可以为网联自动驾驶车辆提供充足可靠的感知信息。

### 发明内容

[0005] 为了解决目前路侧感知技术存在的问题，本发明提供一种基于深度学习的路侧视角超视距全域融合感知系统，包括以下步骤：
[0006] 步骤1、在路侧布置传感器模组，包括摄像头、激光雷达、毫米波雷达；
[0007] 步骤2、采集传感器数据，包括摄像头的图像数据、激光雷达的点云数据、毫米波雷达的点云数据并进行预处理，包括时间同步、噪声滤波、数据解析、数据拼接；
[0008] 步骤3、将预处理后的传感器数据输入到数据层融合模块进行数据层融合处理；
[0009] 步骤4、将数据层融合处理后的图像数据输入到图像语义分割模块，通过预先构建好的深度学习语义分割模型进行语义理解；将数据层融合处理后的激光雷达点云数据输入到激光雷达点云分割模块，通过预先构建好的点云级别的深度学习分割模型进行点云分割；
[0010] 步骤5、将图像语义分割结果和激光雷达点云分割结果输入到决策层融合模块进行处理，得到最终的感知结果和路侧感知系统的输出信息。

[0011] 进一步的，步骤1中，摄像头、激光雷达、毫米波雷达布置在交叉路口或存在视野盲区的区域，摄像头布置时应使摄像头的采集范围覆盖整个待识别路段，激光雷达布置时应尽量使更多点云落在待识别路段上，毫米波雷达应覆盖每条单行车道的较远区域。
[0012] 进一步的，步骤3中，数据层融合模块对传感器数据的处理步骤如下：
[0013] 步骤3 .1、以图像为基准，限制有效的识别范围；
[0014] 步骤3 .2、将激光雷达点云数据投影到图像的成像平面上，对有效识别范围之外的激光雷达点云进行去除；
[0015] 步骤3 .3、将毫米波雷达点云数据投影到图像的成像平面上，对有效识别范围之外的毫米波雷达点云进行去除；
[0016] 步骤3 .4、根据图像、处理后的激光雷达点云、处理后的毫米波雷达点云构建数据层融合模型并输出数据；构建的数据层融合模型如下式所示：

![image-20220209151732784](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151732784.png)

![image-20220209151818665](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151818665.png)

![image-20220209151827867](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151827867.png)

[0031] 进一步的，步骤4中，对图像数据进行语义理解的处理步骤如下：
[0032] (1)对获得的数据层融合数据进行提取，得到用于图像语义分割的输入数据；
[0033] (2)对获得的用于图像语义分割的输入数据进行减均值预处理；
[0034] (3)利用构建好的图像语义分割深度学习模型进行前向推导运算，得到与输入图片同尺寸的像素级分割结果；
[0035] (4)对得到的分割结果进行形态学运算，得到图像语义分割模块的输出结果；
[0036] 步骤4中，对激光雷达进行点云分割的处理步骤如下：
[0037] (1)对获得的数据层融合数据进行提取，得到用于激光雷达点云分割的输入数据；
[0038] (2)对获得激光雷达点云数据进行预处理，去除地面点云，并将非地面点云处理成固定个数；
[0039] (3)利用构建好的激光雷达点云分割深度学习模型对预处理后的激光雷达点云数据进行分割；
[0040] (4)对分割结果和激光雷达点云输入数据进行处理，得到激光雷达点云分割模块的输出结果。
[0041] 进一步的，对图像数据进行语义理解步骤(3)中所述的图像语义分割深度学习模型的构建方法如下：
[0042] 首先，输入预先采集、标注好的训练集；其次，设计图像语义分割深度学习模型的网络结构和损失函数，并利用训练集进行训练；然后，输入预先采集、标注好的测试集进行测试；最后，在实际场景中部署图像语义分割算法，并依据测试结果和实际部署效果判断是否达到预期效果，如果没有达到，则补充训练集重新训练；
[0043] 进一步的，对激光雷达进行点云分割步骤(3)中所述的激光雷达点云分割深度学习模型的构建方法如下：
[0044] 首先，输入预先采集、标注好的训练集；其次，设计激光雷达点云分割深度学习模型的网络结构和损失函数，并利用训练集进行训练；然后，输入预先采集、标注好的测试集进行测试；最后，在实际场景中部署激光雷达点云分割算法，并依据测试结果和实际部署效果判断是否达到预期效果，如果没有达到，则补充训练集重新训练。
[0045] 进一步的，步骤5中，决策层融合模块对输入数据的处理步骤如下：
[0046] 步骤5 .1、将图像语义分割模块的输出、激光雷达点云分割模块的输出、毫米波雷达点云数据输入到决策层融合模块；
[0047] 步骤5 .2、将激光雷达点云分割模块的输出、毫米波雷达点云数据投影到图像成像空间；
[0048] 步骤5 .3、利用图像语义分割结果构建决策层融合基准数据，基准数据模型如下：

![image-20220209151914728](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151914728.png)

![image-20220209151931487](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151931487.png)

![image-20220209151954296](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209151954296.png)

![image-20220209152007272](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152007272.png)

0080] 进一步的，步骤5 .7中，对激光雷达融合数据、毫米波雷达融合数据调整的方式为：利用优化后的图像标签对落在同一标签区域内的激光雷达点云、毫米波雷达点云标记为同一类别，并将新的标签替代原来的标签；决策层融合模块输出数据包含标签、位置、尺寸信息，实现感知系统对场景内目标的全域感知。
[0081] 本发明的有益效果：
[0082] 本发明可以实现对路侧布置的相机、激光雷达、毫米波雷达异构数据采集和进行数据层融合，并利用深度学习分别处理融合后的图像和激光雷达点云数据，最终利用决策层融合实现融合感知。通过在路侧布置感知系统，并结合图像、激光雷达点云、毫米波雷达点云数据各自的优势，可以提升感知视距，并在多个层面对监控区域进行场景理解，最终为网联自动驾驶车辆提供充足可靠的感知信息。
[0083] 本发明的环境感知系统继承了深度学习算法高准确率的特点；同时，本发明采用数据层融合和决策层融合相结合的融合方式，剔除多余数据提升算法性能并保证系统获取的信息具有足够的冗余度，提升了系统的鲁棒性；另外，系统综合考虑多个传感器工作特性，结合毫米波雷达识别距离远的特点进一步提升了对远距离目标识别的可靠性；最后，系统输出的数据包括标签、位置、尺寸等多方位信息，使感知系统实现了对场景内目标的多层次全域感知。

### 附图说明

[0084] 图1为本发明路侧视角超视距全域融合感知系统传感器布置示意图；
[0085] 图2为本发明的软件框架图；
[0086] 图3为本发明的工作流程示意图；

[0087] 图4为本发明中数据层融合模块的工作流程示意图；
[0088] 图5为本发明中图像算法模块的工作流程示意图；
[0089] 图6为本发明中激光雷达算法模块的工作流程示意图；
[0090] 图7为本发明中决策层融合模块的工作流程示意图。

### 具体实施方式

[0091] 请参阅图1‑7所示：
[0092] 本发明提供的一种基于深度学习的路侧视角超视距全域融合感知系统，包括相机模块、激光雷达模块、毫米波雷达模块、图像拼接模块、毫米波雷达拼接模块、数据层融合模块、图像算法模块、激光雷达算法模块、毫米波雷达转发模块、决策层融合模块和结果输出模块；具体包括以下步骤：
[0093] 步骤1、在路侧的龙门架上布置传感器模组1，即相机模块、激光雷达模块和毫米波雷达模块，包括至少四个摄像头2、一个激光雷达3和至少两个毫米波雷达4；摄像头2、激光雷达3、毫米波雷达4布置在交叉路口或存在视野盲区的区域，摄像头2布置时应使摄像头2的采集范围覆盖整个待识别路段，激光雷达3布置时应尽量使更多点云落在待识别路段上，毫米波雷达4应覆盖每条单行车道的较远区域。
[0094] 步骤2、采集传感器数据，包括摄像头2的图像数据、激光雷达3的点云数据、毫米波雷达4的点云数据并在图像拼接模块、毫米波雷达拼接模块中进行预处理，包括时间同步、噪声滤波、数据解析、数据拼接；
[0095] 步骤3、将预处理后的传感器数据输入到数据层融合模块进行数据层融合处理；数据层融合模块对传感器数据的处理步骤如下：
[0096] 步骤3 .1、以图像为基准，限制有效的识别范围；
[0097] 步骤3 .2、将激光雷达点云数据投影到图像的成像平面上，投影公式如下式所示：

![image-20220209152126864](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152126864.png)

![image-20220209152140781](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152140781.png)

[0112] 步骤4、将数据层融合处理后的图像数据输入到图像算法模块即图像语义分割模块，通过预先构建好的深度学习语义分割模型进行语义理解，处理步骤如下：
[0113] (1)对获得的数据层融合数据进行提取，得到用于图像语义分割的输入数据；
[0114] (2)对获得的用于图像语义分割的输入数据进行减均值预处理；
[0115] (3)利用构建好的图像语义分割深度学习模型进行前向推导运算，得到与输入图片同尺寸的像素级分割结果；所述的图像语义分割深度学习模型的构建方法如下：
[0116] 首先，输入预先采集、标注好的训练集；其次，设计图像语义分割深度学习模型的网络结构和损失函数，并利用训练集进行训练；然后，输入预先采集、标注好的测试集进行测试；最后，在实际场景中部署图像语义分割算法，并依据测试结果和实际部署效果判断是否达到预期效果，如果没有达到，则补充训练集重新训练；
[0117] (4)对得到的分割结果进行形态学运算，得到图像语义分割模块的输出结果；
[0118] 同时，将数据层融合处理后的激光雷达点云数据输入到激光雷达算法模块即激光雷达点云分割模块，通过预先构建好的点云级别的深度学习分割模型进行点云分割，处理步骤如下：
[0119] (1)对获得的数据层融合数据进行提取，得到用于激光雷达点云分割的输入数据；
[0120] (2)对获得激光雷达点云数据进行预处理，去除地面点云，并将非地面点云处理成固定个数；
[0121] (3)利用构建好的激光雷达点云分割深度学习模型对预处理后的激光雷达点云数据进行分割；所述的激光雷达点云分割深度学习模型的构建方法如下：

[0122] 首先，输入预先采集、标注好的训练集；其次，设计激光雷达点云分割深度学习模型的网络结构和损失函数，并利用训练集进行训练；然后，输入预先采集、标注好的测试集进行测试；最后，在实际场景中部署激光雷达点云分割算法，并依据测试结果和实际部署效果判断是否达到预期效果，如果没有达到，则补充训练集重新训练；
[0123] (4)对分割结果和激光雷达点云输入数据进行处理，得到激光雷达点云分割模块的输出结果。
[0124] 步骤5、图像算法模块和激光雷达算法模块将图像语义分割结果和激光雷达点云分割结果输入到决策层融合模块进行处理，毫米波雷达转发模块将毫米波雷达点云数据输入到决策层融合模块进行处理，处理步骤如下：
[0125] 步骤5 .1、将图像语义分割模块的输出、激光雷达点云分割模块的输出、毫米波雷达点云数据输入到决策层融合模块；
[0126] 步骤5 .2、将激光雷达点云分割模块的输出、毫米波雷达点云数据投影到图像成像空间；
[0127] 步骤5 .3、利用图像语义分割结果构建决策层融合基准数据，基准数据模型如下：

![image-20220209152229824](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152229824.png)

![image-20220209152254934](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152254934.png)

![image-20220209152306524](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152306524.png)

![image-20220209152317217](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152317217.png)

![image-20220209152325910](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152325910.png)

![image-20220209152427301](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152427301.png)

![image-20220209152514877](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152514877.png)

![image-20220209152540038](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152540038.png)

![image-20220209152548153](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152548153.png)

![image-20220209152827098](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152827098.png)

![image-20220209152852185](https://gitee.com/er-huomeng/l-img/raw/master/l-img/image-20220209152852185.png)

