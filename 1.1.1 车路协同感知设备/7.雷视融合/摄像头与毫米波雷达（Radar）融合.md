- [摄像头与毫米波雷达（Radar）融合](https://www.cnblogs.com/wujianming-110117/p/12482145.html)

**摄像头与毫米波雷达（Radar）融合**

Input：

（1）图像视频分辨率（整型int）

（2）图像视频格式 （RGB，YUV，MP4等）

（3）毫米波雷达点云信息（点云坐标位置x,y，浮点型float）

（4）摄像头标定参数（中心位置（x,y）和5个畸变

系数（2径向，2切向，1棱向），浮点型float）

（5）摄像头初始化参数（摄像头初始位置和三个坐标方向

的旋转角度，车辆宽度高度车速等等，浮点型float）

Output：

（1）利用kalman滤波融合后的摄像头与毫米波雷达

点云信息（点云坐标位置x,y，浮点型float）

（2）融合后的image/video （RGB，YUV，MP4等）

（3）目标物与车辆的距离（浮点型float）

（4）目标物的识别  （整型int）

## **1.** **功能定义**

时间戳的融合。

摄像头的时间戳和雷达的世家戳是不一致的。先要实现时间戳上的融合。

空间上的融合。

将摄像头中检测得到的目标物转换到世界坐标系中，来和雷达中所检测得到的点远信息的融合。

速度融合。

雷达能够给出准确的位置和速度信息。摄像头的速度则可以通过卡尔曼滤波获得。通过速度融合能够准确地找到摄像头的位置和雷达的点源的一一对应关系。

融合算法。融合算法的准确性决定了融合的结果。

摄像头测距。

由于雷达的测距是点源信息，如果要得到摄像头上图像连续的距离还是需要通过像素获得。因此，需要通过雷达来标定摄像头的外参。

融合平台的开发。融合之前分别获得雷达，摄像头，摄像头检测的结果，其中又包括了滤波，摄像头的测距等算法。

## **2.** **技术路线方案**

视觉摄像头与雷达各有所长。

毫米波雷达与摄像头融合介绍

1）雷达测速

范围：-50米/秒～50米/秒，误差error：0.1米/秒～0.2米/秒

2）雷达测距

120米～130米，误差error：2.5%以内，单目摄像头误差error：8～10%

3）融合方法：特征融合，数据融合。

视觉摄像头的优点在于：

1)  可以完成道路环境参数识别（车道检测、前方车辆检测、行人检测、道路标志检测、交通标志检测）

2)  基于双目摄像头可以相对准确的计算物体距离

缺点在于：

1)  识别率与模型算法、外界视觉环境条件相关（雨天、雾霾、黑夜）

2)  识别范围为视距内范围

解决或优化方案：

1）提高摄像头的像素，若摄像头的像素提高，能够提高检测的精度，能够一定程度上提高测距的精度。

2）自适应标定，这里需要开发自适应的标定算法，根据不同的路况来进行路面的自适应标定来降低误差。

3）降低摄像头的放置的位置。降低摄像头的z方向的高度能够在图像上增加y方向上车到灭点的像素数量，从而提高测距精度。

雷达的优点在于：

1)  可以全天候使用，不受光照和天气等因素影响

2)  可远距离使用，对目标探测的角度、距离及相对速度探测准确度高于视觉

3) 激光雷达在进行3D扫描过程中，除了对目标进行检测外，还可以对环境进行感知

缺点在于：

1)  难以识别出人（非金属物品）、自行车等小物体

2)  弯曲隧道或者障碍物较多的情况下，雷达波反射误判严重

3)  随着市场产品对于检测精度的要求越来越高，仅仅使用单一的视觉或雷达技术不足以适应高

精度的驾驶需要。在未来，视觉与雷达ADAS技术肯定是走向有机的融合与结合，取长补短提高判断的准确性。

解决或优化方案：

实现摄像头和雷达的融合。

摄像头和雷达的融合是很多做ADAS当前所关注的关键问题之一。因为单纯摄像头和雷达都无法解决测距问题。不仅在测距，今后可能所应用到的高精度地图也都是需要使用摄像头和雷达的融合才能够实现。

当前寻求到最优的方案是实现摄像头和雷达的融合。摄像头测距的准确性较低，雷达测距的准确性较高，然而没有点源的身份信息。雷达和摄像头的特点对比如下。

 ![img](https://img2020.cnblogs.com/i-beta/1251718/202003/1251718-20200312193136441-1255791827.png)

表1. radar和camera融合性能对比

摄像头在雨雾、黑暗的环境下就会“失明”，强光和弱光环境它也不能正常工作。与光学传感器相比，雷达在分辨率上明显较差，不过它在测距测速功能和恶劣天气下明显更胜一筹。虽然光学传感器在恶劣天气下能力受限，但它依然能识别色彩（交通灯和路标），而且在分辨率上依然有优势，可以说每种传感器都有自己的优势也有自己的软肋。想做到完美的传感器融合，就要接受不同传感器的输入，并利用综合信息更准确的感知周边环境，其得出的结果比不同传感器各自为战要好得多。

融合算法中有特征融合和数据融合两种融合。如下图所示：

 ![img](https://img2020.cnblogs.com/i-beta/1251718/202003/1251718-20200312193148933-210665369.png)

图1. 特征融合（左）与数据融合（右）

如图1所示，左侧是特征融合，右侧是数据级融合。

特征融合分别在自己的模块内完成目标的分类和跟踪进行融合，模块间分别通过CAN总线进行数据交互。数据级融合在同一模块内进行融合，无需数据交换。数据及融合的等级较高，但是需要获得传感器的底层参数，当前无法获得。因此当前采取的是特征融合。  

## 3. **关键技术参数和性能指标**

当前各大算法公司给出的测距性能普遍在50米精度在5%，100米精度在10%。根据调研，算法公司通常给出的是一个平均的误差。实际远距离测距的误差可能会比较大。近距离的误差可能相对比较好一些。远距离的误差一直是算法中的难点，因此分段设置测距精度是合理的。

结合毫米波的融合，测距的精度目标是能够实现如下：

1）50米以内精度2%~3%。

2）100米以内5%~8%。

3）给出TTC时间和警告等级。