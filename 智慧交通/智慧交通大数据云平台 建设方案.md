# 智慧交通大数据云平台建设方案

# 系统总体设计

## 云计算系统设计方案概述

### 系统基本功能

按照全省公安机关信息化建设总体规划， 为实现对重点车辆的自动比对和动态管控、对异常车辆行踪的自动研判预警、 对特定车辆行车轨迹的自动生成、 对重要节点道路交通信息的远程再现、 对基层单位和执勤民警的勤务实施管理等建设目标，为交通管理、治安管控、侦查破案、巡逻防范、反恐处突等各项公安工作提供服务保障。

系统的基本功能和性能如下：

- 海量数据存储

- 能够对百亿级的海量交通监控数据进行存储，保存时间为 2 年。

- 海量数据实时处理、实时入库、生成索引能够对百亿级的海量交通监控数据进行实时处理， 能够处理每天 500 万条记录，能够实时处理约 60 条/ 秒的实时数据流量。

- 百亿级数据秒级查询能力、秒级实时业务响应高效实时数据查询架构，提供秒级响应时间， 1 天的记录能在 5 秒钟内查询出来，一周记录能在 15 秒内查询出来。

### 主要设计思想和设计目标、设计原则

设计思想：将海量数据分解到由大量 X86架构计算机构成的低成本云计算平台上进行实时处理， 依靠分布式云计算软件进行容错， 从而提升智慧交通云平台海量数据分析的实时性和性价比。

设计目标： 利用大量性价比高的计算机， 建立云计算平台， 能够对流量超过500w条/ 天的原始交通监控数据流进行实时处理。系统具有可动态可伸缩性、高度容错性和响应实时性，达到较之传统方案有一个数据量级的性能价格比提升。

设计原则：

（1）前瞻性技术与实际应用环境相结合

本项目是既是先进技术应用示范项目， 又是工程实施型项目。 把握技术正确性和先进性是前提， 但是前瞻性技术实施必须在云计算平台的实际应用环境和实际监控流量的基础上进行， 必须结合云计算平台的实际情况进行研究和开发， 只

有与实际应用环境相结合才有实际应用价值。

（2）学习借鉴国外先进技术与自主创新相结合

在云计算平台用于超大规模数据处理方面，国内外几乎是在一个起跑线上；但在关键技术研究及既往的技术积累方面， 国外一些大 A 有着明显的优势。同时，智慧交通云平台所将要面对的交通监控数据流高达 500w条/ 天，是一个世界级的云计算应用。 我们将积极学习借鉴国外先进的云计算技术， 同时与自主创新相结合，形成功能强大、 性能卓越的能够满足实际应用环境需求的云计算数据处理和分析平台。

（3）遵循公安 320 工程相关标准规范

本项目的设计将严格遵循公安 320 工程相关标准规范。

### 智慧交通云平台的云计算解决方案

在公安网内部，构建若干 X86架构计算 / 存储节点，虚拟出海量存储空间、处理能力和数据管理能力。 同时研制面向应用的分布式数据处理软件， 满足数据汇总、数据上报、数据入库、数据查询、数据计算和数据管理等应用需求。

![image-20210720113111030](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210720113111030.png)

### 系统的主要技术特点

实时性：平台在高效率并行分布式软件的支撑下， 可以实时完成交管数据入库、分析和管理工作，如数据汇总、数据上报、数据入库、数据查询、数据计算和数据管理等。 海量数据入库不会出现数据堆积现象， 各类分析和查询工作基本都在秒级完成，具有前所未有的高效性。

高可靠性 ：基于对云计算可靠性深厚的研究积累， 彻底解决了当前分布式计算平台易出现的单点故障问题。 任何一个节点出现故障， 系统将自动屏蔽， 而且不会出现丢失数据的现象。包括查询任务分配节点、计算任务分配节点、 HDFS元数据节点、 HDFS数据存储节点、 MapReduce Job Tracker 节点、 MapReduce Worker 节点、HBase管理节点、 HBase Region 节点等。

可伸缩性： 在不停机的情况下，增加节点，平台的处理能力自动增加；减少节点，平台的处理能力自动缩减。这样，可以做到与云计算平台的无缝对接，根据计算和存储任务动态地申请或释放资源，最大限度地提高资源利用率。

高性价比：采用 X86架构廉价计算机构建云计算平台， 用软件容错替代硬件容错，大大节省成本。 在目标性能和可靠性条件下， 可比传统的小型机加商用数据库方案节省 10 倍左右的成本。

全业务支持： 采用分布式数据库模式， 绝大部分海量数据存放于分布式平台并进行分布式处理， 少量实时性要求很高的数据存放于关系数据库中， 可支撑各种类型的业务。不仅支撑查询、统计、分析业务，还可支撑深度数据挖掘和商业智能分析业务。

## 系统总体构架

### 系统基本组成与构架

智慧交通云平台是一个处于交管数据采集与交管数据监测应用之间的系统。

从系统基本组成与构架上来看， 该共享平台由 7 个主要部分组成： 历史数据汇总处理系统，上报数据上报系统，实时数据入库系统，交管数据存储系统，交管数据查询分析应用系统，数据管理系统以及系统管理。

### 系统功能构架

智慧交通云平台需要提供的7 大主要功能描述如下。

（1）历史数据汇总处理系统

历史数据汇总处理主要负责把南京市6 个分散的数据中心的历史数据， 进行读取解析处理，并将处理后的历史数据汇入一个统一的数据中心。

在内部处理模块上， 历史数据汇总系统主要包括三个模块： 读取模块、解析模块和汇总模块。 读取模块主要负责各个数据中心历史数据的读取处理， 解析模块主要负责把读取到的历史数据解析成合理的数据格式， 而汇总模块主要负责把解析好的历史数据上传到统一的数据中心。

在系统构架上， 为了满足 6 个分散的数据中心处理需要， 需要在每一个数据中心处安装一个数据汇总程序。

（2）上报数据上报处理信系统

上报数据上报处理负责把市数据中心的数据， 按照一定的需求 （按时间段或一定的数据量），上报给省厅数据中心。

在内部处理模块上 , 上报数据上报系统主要包括三个模块：读取模块、解析模块和上报模块。 读取模块主要负责市数据中心需要上报数据的读取处理， 解析模块主要负责把读取到的数据解析成合理的数据格式， 而上报模块主要负责把解析好的数据上传到的省厅数据中心。

在系统构架上， 为了满足市数据中心处理需要， 需要在市数据中心处安装一个数据上报程序。而省厅数据中心需要提供数据上报的接口。

（3）实时数据入库系统

实时数据入库系统主要负责全市每个卡口产生的数据实时入库。

在内部处理模块上， 实时数据入库系统主要包括三个模块： 接受模块、解析模块和数据入库模块。 接受模块主要负责接收每个卡口产生的数据流，解析模块主要负责把接受到的数据流解析成合理的数据格式， 而数据入库模块负责把解析好的数据加入到市数据中心。

在系统架构上， 为了使每个卡口的数据能实时入库市数据中心， 需要在每一个负责接受卡口数据的工控机上安装一个实时数据入库系统。

（4）交管数据存储系统

原始交管数据， 将全部存储在智慧交通云平台的云存储资源中。 

资源池提供两种存储资源： 一种是结构化数据存储资源， 用于存储少量的接口中间数据； 另一种是分布式文件系统， 用于存储海量的非结构化数据。 为了满足适应数据量、数据特征和查询处理的不同需求，将采用一种混搭式的数据存储方案。

对容量巨大、 常规数据库难以处理的数据， 如交管数据， 将主要存储在基于HDFS的分布式文件系统中；这些数据将通过 HDFS接口进行访问和计算处理。而对于部分数据量不大、 且查询响应性能要求很高的数据， 如用于报警比对的中间数据，将被存放在关系数据库中。关系数据库将采用 Sybase ASE版本。这些数据将通过结构化数据存储访问接口（如 JDBC）进行访问。

在存储构架上， 若以存储 3 年的原始交管数据、 报警信息数据和针对快速查询建立的索引数据，在 10000 条/s 的交管数据流量下，将大约需要 512TB的存储容量，按照每个存储节点 16TB的存储容量，加上少量的冗余节点，将需要 32个存储节点。

（5）交管数据查询分析应用系统

交管数据查询分析应用主要提供包括实时监控、 报警监控、车辆轨迹与回放、电子地图、报警管理、布控管理、设备管理、事件检测报警、流量统计和分析等功能。

车辆轨迹查询处理时， 由于交管数据量巨大， 难以存储在常规的关系数据库中，而如果直接存储在 HDFS或 HBase中又难以保证查询效率。为此，需要考虑对交管数据进行索引处理，并将索引数据存储在 HDFS或 Hbase中。为了建立交管数据索引， 需要在交管数据传送到云存储系统中时， 进行实时的索引处理。 但由于交管数据流量巨大， 需要调度使用多台服务器节点进行并行处理。 

此外，用户从客户端发起以上各种数据查询分析任务时，也会产生大量并发的查询任务。

以上各种查询分析计算任务的处理将需要考虑在计算集群上进行并行化任务调度和负载均衡处理。 这些并行计算任务及负载均衡处理将使用 Zookeeper 基于计算集群完成统一的控制和实现。

在系统构架上，以上查询分析计算任务将需要使用一个大规模数据并行计算集群。在编程实现上，存储在数据库中的数据将使用常规的数据库查询语言实现；对存储在分布式文件系统中的交管数据， 针对不同的处理要求， 在数据量极大而处理实时性要求不是特别高的情况下， 为了方便对海量数据的并行处理， 将采用MapReduce编程方式实现；而对于那些实时性要求很高的查询分析计算，由于MapReduce启动作业需要较长的时间开销，将不适合采用 MapReduce编程实现，而需要用非 MapReduce编程方式实现。

（6）数据管理系统

在实际使用中， 可能用户会对某一时间段或者类型的数据特别关心， 就可以通过数据管理系统查询并导出这部分数据以供使用。

包括数据查询和数据导出两大部分。 数据查询让用户以自定义的条件查询出数据，而数据导出就是将这些数据以合理的格式导出到数据中心以外。

（7）系统管理

系统管理主要包括智慧交通云平台的配置管理、 系统安全管理、 系统用户管理，以及数据备份、系统故障监测复等管理维护功能。

配置管理是其中最主要的部分， 是系统各个模块正常运行的基础。 系统应能够对网络地址、设备地址等进行配置； 能够对用户做权限管理， 以防止数据外泄；并能及时有效的对数据进行备份和故障检测等工作， 防止数据的意外丢失。 系统应支持树图、数据表格、网络拓扑图形式展示配置数据。

### 系统总体构架与功能模块

基于以上基本的系统组成和功能构架， 系统的详细总体构架和功能模块设计如图所示。

![image-20210720113455900](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210720113455900.png)

上图中，自底向上分为五个层面。 最下层是硬件平台层， 将使用南京市公安局云计算中心所提供的计算、 存储和网络资源。 从系统处理系统的角度看， 这一层主要包括云存储计算集群， 此外还包括接口和管理服务器、 包括用于实现客户端访问的 Web服务器。

第二层是系统软件层， 包括移动的云存储系统软件， 综合分析云计算软件平台，以及 Web服务软件等。云存储系统将提供基于 Sybase ASE关系数据库的结构化数据存储访问能力，以及基于 HDFS的分布式文件系统存储访问能力，分别提供基于 JDBC/SQL的数据库访问接口以及 HDFS访问接口。综合分析云计算软件平台可提供对 HDFS、Hbase数据的访问， 并提供 MapReduce编程模型和接口、 以及非 MapReduce模型的编程接口，以及用于实现并行计算任务负载均衡和服务器单点失效恢复的 Zookeeper。

第三层是智慧交通云平台中的数据层， 包括原始交管数据、 索引数据、用于分析的中间数据、以及系统配置数据等。其中，原始交管数据、索引数据等海量数据将存储在南京公安局云存储系统的 HDFS分布式文件系统中， 用 HDFS接口进行存储和访问处理； 而其它用于分析的中间数据等数据量不大、 但处理响应性能要求较高的数据，将存储在云存储系统的关系数据库系统中，用 JDBC/SQL进行存储和访问处理。

第四层是交管数据处理软件层， 主要完成智慧交通云平台所需要提供的诸多功能，包括实时监控、报警监控、车辆轨迹查询与回放、电子地图、报警管理、布控管理、设备管理、事件检测报警、流量统计和分析、系统管理等功能。

最上层是客户端用户界面软件， 主要供用户查询和监视相关的数据信息， 除了事件检测报警不需要用户界面外，其它部分都需要实现对应的用户界面。

## 系统基本功能与处理方案

智慧交通云平台通过实时数据入库系统接入采集层的交管数据， 数据分配进入负载均衡机， 负载均衡机根据集群各节点负载情况， 动态分配交管数据到各存储处理机， 进行报警检测、 建立索引等处理， 同时将交管数据存入分步式存储系统。

### 负载均衡机功能

监控所集群机器负载情况， 动态分配交管数据。 监控所有集群机器， 如果发现问题，那么就把分配给这台机器的交管数据重新分配到其他机器， 去除单点故障，提高系统可靠性。

负载均衡机采用Paxos 算法解决一致性问题，集群在某一时刻只有一个Master 负责均衡能力， 当 Master 宕机后，其他节点重新选举 Master。保证负载均衡机不会存在单点问题，集群机器一致性。

### 实时业务

对于实时性要求高的业务应用，如：实时监控、实时报警，走实时专道。

## 数据存储功能与处理方案

交管数据处理： 接收来自数据汇总和数据入库系统的交管数据， 索引模块实时生成索引，以提高查询速度。生成的索引存储到 HDFS中，以供查询交管数据使用。

专题业务分析， 通过 MapReduce并行计算， 同期提取业务数据， 将结果分存两路，一路存入 Hbase或日志详单存储，一路存入关系型数据库。

报警数据处理智慧交通云平台对接收到的实时交管数据进行计算， 以判断这辆车有没有符合报警条件。如果符合，会对报警信息入库，并同时通过对外实时报警接口，将报警信息迅速展示到用户界面上。

## 网络管理

### 服务器间网络安全检查

系统自管理通过启用网络安全检查进程（ netinspect ）, 定期检查整个系统的网络状况， 并上报各服务模块网络流量信息， 在终端形成网络拓扑图， 实时在界面呈现各节点网络状态， 管理员也能及时了解， 各服务模块的网络流量机承载的负荷。若出现网络故障， netinspect 进程实时上报故障情况，在网络拓扑图上以报警方式提示， 或以短信的方式提示， 便于管理员及时发现问题， 并恢复网络故障，确保系统在安全的网络环境下运行。

### 服务模块进程监控管理

系统自管理通过启用服务模块运行状态检查进程（ proinspect ）, 定期检查整个系统的服务模块进程运行状况， 并上报各服务模块进程的运行状态信息， 在终端将运行的进程的状态以表格形式显示， 定时更新进程的运行状态信息。 通过它管理员也能及时了解， 各服务模块的进程运行负荷。 若在固定的时间内没有更新，视为进程运行故障， 启动主机代理自动恢复故障进程， 保障各服务模块进程持续稳定的运行的状态。

### 系统性能监控管理

系统自管理通过启用服务模块性能检查进程 （serverinspect ）, 定期检查整个系统的各服务器性能指标，包括 CPU开销、内存占用、 IO 峰值、网络流量、连接数等。 并上报各服务性能指标， 在终端形成拓扑图， 实时在界面呈现各节点服务器性能状态， 管理员也能及时了解， 各服务节点处理性能及资源开销。 若性能持续高负荷， 拓扑图上以报警方式提示， 或以短信的方式提示， 便于管理员及时发现问题， 查找问题的来源或重新评估服务器配置情况， 为系统稳定运行提供一个确实可靠的标准。

### 系统日志分析处理

系统各服务模块在运行期间写日志文件，将进程的模块编号、服务器的 IP、出错页码等日志的状态（错误、告警、提示）等级别的信息保存磁盘文件，供工程师来分析系统运行状态。同时日志分析进程 (loganalyse ）分析日志文件，将重要的日志信息，进行对比、分析并汇总后，生产统一格式的日志信息，提取出来，写入的数据库表中， 终端管理通过查询界面来来显示， 能及时了解到系统的运行的状态。

### 系统运行状态及报警处理

系统运行报警分为以下几种：

服务器运行状态报警

服务器网络状态报警

服务模块进程报警

日志模块状态报警

## 系统可靠性与扩展性

### 系统可靠性

#### HDFS可靠性概述：

HDFS包括元数据节点 (Namenode)和数据节点 (Datanode) ，Namenode是一个中心服务器，负责管理文件系统的 Namespace和客户端对文件的访问。 ，Datanode在集群中一般是一个节点一个， Datanode是文件系统中真正存储数据的地方。

#### DataNode所在机器挂了怎么办？

HDFS(Hadoop Distributed File System) 默认的最基本的存储单位是 64M的数据块（ block ）。 一个文件对应的所有 BLOCK全部按照一定的部署策略存在于 DataNode上，文件的所有 block 为了容错都会被复制 （一般为 3 份），每个文件的 block 大小和 replication 因子都是可配置的。 

Datanode 每 3 分钟向Namenode发送心跳，如果 10 分钟 datanode 没有向 Namenode发送心跳，则Namenode认为该 Datanode 已经 dead，Namenode将取出该 Datanode 上对应的block ，对其进行复制。

#### Namenode挂了怎么办？ 

Namenode主控服务器，为了避免主节点失效而影响整个系统正常工作，我们采用基于 HDFS的改进方案 Avatar ，同时可开启两个Namenode，主 Namenode和 secondNamenode，实际工作的只有主 Namenode。主Namenode将所有关于文件和目录的操作记录都会写入日志，并定时序列化到本地做镜像，并且保存到本地的 NFS服务器，同时 secondNamenode读取主 Namenode所在 NFS服务器的日志并对镜像日志做CheckPoint 。故障后，secondNamenode升级为 Namenode，通过镜像数据和文件日志迅速恢复系统。数据服务器可通过分布式协同服务机制得知关于主控服务器的更迭情况， 然后向新的主控注册并继续发送心跳。

#### HBase可靠性概述：

HBase系统由 HBase集群和 ZooKeeper集群组成。 HBase的可靠性由其自身的 ZooKeeper机制保证。 HBase包括 Hregion 服务器群和 Master 主服务器构成。

Master 负责管理 Hregion 。物理上，一张表是被拆成多个块， 一张完整的表格是保存在多个 Hregion 上面的。

#### master 挂掉怎么办？

由于 master 只维护表和 region 的元数据，因此 master 下线短时间内对整个 hbase 集群没有影响， master 保存的信息全是可以冗余信息（都可以从系统其它地方收集到或者计算出来） ，因此，启动 HBase 时可以再启动一个备用的master，实际工作的只有主 master，当主 master 所在节点宕机，会自动切换到备用 master 所在节点。

#### Hregionserver 挂掉怎么办？

物理上，表格分为多个 Region 一张表是被拆成多个块，一张完整的表格是保存在多个 Hregionserver 上面的。并且分布在多台 Hregionserver 中，物理上所有数据存储在 Hadoop的 HDFS上，由一些子表服务器来提供数据服务， 提供服务时，子表先查 HMemcache，如果没有，再查 HDFS上的 HStore，由 HDFS来保证

数据的可靠性。如果丢失 Region 的数据所在节点的 datanode 宕机， HDFS会自动映射到其他节点，从而保证 Region 数据的可靠性。

#### ZooKeeper挂掉怎么办？

Zookeeper 分为 2 个部分：服务器端和客户端。启动 Zookeeper 服务器集群环境后，多个 Zookeeper 服务器在工作前会选举出一个 Leader，在接下来的工作中这个被选举出来的 Leader 死了，而剩下的 Zookeeper 服务器会知道这个Leader 死掉了，在活着的 Zookeeper 集群中会继续选出一个 Leader，选举出leader 的目的是为了可以在分布式的环境中保证数据的一致性。

#### MapReduce可靠性概述：

MapReduce整体上可以分为这么几条执行的线索， JobTracker 与 JobTracker是一个 master 服务，软件启动之后 JobTracker 接收 job ，负责调度 job 的每一个子任务 task 运行于 TaskTracker 上，并监控它们，如果发现有失败的 task就重新运行它。 一般情况应该把 JobTracker 部署在单独的机器上。 TaskTracker是运行于多个节点上的 slaver 服务。TaskTracker 主动与 JobTracker 通信，接收作业，并负责直接执行每一个任务。 

TaskTracker 都需要运行在 HDFS的DataNode上，JobTracker0 挂掉怎么办？在系统启动时同时启动备份 JobTracker1 节点，当 JobTracker0 节点宕机时，ZooKeeper 会在其上启动 JobTracker 进程替代JobTracker0 节点，虚拟 IP 会指向此节点， TaskTracker 会注册到此节点上， 未完成的 MapReduce作业会被 ZooKeeper 调度到此节点上重新执行。

#### TaskTracker 挂掉怎么办？

 JobTracker 是一个 master 服务，软件启动之后JobTracker 接收 job ，负责调度 job 的每一个子任务 task 运行于 TaskTracker上，并监控它们，如果发现有失败的 task 就重新运行它。并且将其负责的 task分配给其他 TaskTracker 上。

### 系统扩展性

已有的 Hadoop集群规模

Hadoop 是一个相当有弹性和扩展性的平台，它既可以在成千上万的机器上跑，也可以在很小规模上运行。目前最大的 Hadoop集群有四千台机器。

#### Hadoop扩展优势：

与其它分布式系统相比，使用Hadoop的好处在于它的水平的可扩展性，在少量结点上， 用 Hadoop处理有限的数据时， 不能展示 Hadoop的性能，因为开始Hadoop 程序相关的代价比较高，其它并行 / 分布程序方式，比如 MPI (Message Passing Interface) 可能在 2 台，4 台或许 10 多台计算机上有更好的性能，尽管在少量机器上协同工作在这种系统上也许会取得更好的性能，但这种为性能所要付出的努力是非线性的增长。 用其它分布式框架所写的程序在从十台机器的级别到成百上千台机器需要大量的重构工作， 这也许要程序重写几次， 并且其它框的基础元素会限制应用的规模大小。但是特别设计的 Hadoop有着水平的可扩展，一个 Hadoop程序写完后， 在 10 个结点上运行， 如果迁徙到更大的集群上运行，几乎不需要做什么工作， Hadoop 平台会管理数据和硬件资源并提供与可用资源成比例的可靠性能。

#### Hadoop扩展方法：

HBase集群具备线性扩展功能，只需要将配置好的 region server 节点加入到集群中。

MapReduce集群具备线性扩展功能， 只需要将配置好的 TaskTracker 节点加入到集群中， JobTracker 节点就会将 Map或 Reduce任务分配给此节点处理。

HDFS具备线性扩展功能，只需要将配置好的 DataNode节点加入到集群中，

并且在集群空闲时执行 balancer 工具以平衡集群中 DataNode的数据块负载。

# 数据存储系统

## 海量数据分布式数据存储构架

云计算是一种超级的计算模式，可以把网络中的计算机虚拟为一个资源池，将所有的计算资源集中起来， 并用特定软件实现自动管理， 使得各种计算资源可以协同工作，这就使得处理数量巨大的数据成为了可能。

基于云计算的海量数据存储模型， 是依据云计算的核心计算模式 MapReduce，并依托实现了 MapReduce 计算模式的开源分布式并行编程框架 Hadoop，将存储模型和云计算结合在一起，实现海量数据的分布式存储。

MapReduce 是云计算的核心计算模式，是一种分布式运算技术，也是简化的分布式编程模式，用于解决问题的程序开发模型， 也是开发人员拆解问题的方法。

MapReduce 模式的主要思想是将自动分割要执行的问题，拆解成 Map（映射）和Reduce（化简）的方式。

在数据被分割后通过 Map 函数的程序将数据映射成不同的区块，分配给计算机集群处理达到分布式运算的效果，在通过 Reduce 函数的程序将结果汇整，从而输出开发者需要的结果。

 MapReduce 借鉴了函数式程序设计语言的设计思想，其软件实现是指定一个 Map 函数，把键值对 (key/value) 映射成新的键值对(key/value) ，形成一系列中间结果形式的 key/value 对，然后把它们传给Reduce(规约 ) 函数，把具有相同中间形式 key 的 value 合并在一起。 

Map 和Reduce 函数具有一定的关联性。

Hadoop 是一个实现了 MapReduce 计算模型的开源分布式并行编程框架， 程序员可以借助 Hadoop 编写程序，将所编写的程序运行于计算机集群上，从而实现对海量数据的处理。 此外，Hadoop 还提供一个分布式文件系统 (HDFS）及分布式数据库（ HBase）用来将数据存储或部署到各个计算节点上。借助 Hadoop 框架及云计算核心技术 MapReduce 来实现数据的计算和存储， 并且将 HDFS 分布式文件系统和 HBase 分布式数据库很好的融入到云计算框架中，从而实现云计算的分布式、并行计算和存储，并且得以实现很好的处理大规模数据的能力。

在 Hadoop 的系统中，会有一台 Master ，主要负责 Namenode的工作以及JobTracker 的工作。 JobTracker 的主要职责就是启动、跟踪和调度各个 Slave的任务执行。还会有多台 Slave，每一台 Slave 通常具有 DataNode的功能并负责 TaskTracker 的工作。TaskTracker 根据应用要求来结合本地数据执行 Map任务以及 Reduce任务。

主服务控制集群相当于控制器部分， 主要负责接收应用请求并且根据请求类型进行应答。 存储节点集群相当于存储器部分， 是由庞大的磁盘阵列系统或是具有海量数据存储能力的集群系统，主要功能是处理数据资源的存取。 

HDFS 和Hbase 用来将数据存储或部署到各个计算节点上。 

Hadoop 中有一个作为主控的Master，用于调度和管理其它的计算机（将其称之为 TaskTracker ），Master 可以运行于集群中任一台计算机上。 

TaskTracker 负责执行任务，必须运行于DataNode上，DataNode 既是数据存储节点，也是计算节点。 

Master 将 Map 任务和 Reduce 任务分发给空闲的 TaskTracker ，让这些任务并行运行，并负责监控任务的运行情况。如果其中任意一个 TaskTracker 出故障， Master 会将其负责的任务转交给另一个空闲的 TaskTracker 重新运行。用户不直接通过Hadoop 架构读取及 HDFS 和 Hbase 存取数据，从而避免了大量读取操作可能造成的系统拥塞。用户从 Hadoop 架构传给主服务控制集群的信息后，直接和存储节点进行交互进行读取操作。

## 适应应用需求的混合存储策略

混合存储策略可以简述为 HDFS分布式文件系统用来存储海量数据， 可以根据存储的数据类型建立索引， HBase也可用来存储海量数据，其由查询条件建立索引表， Database 对小型数据的存储处理。

分布式文件系统 HDFS是一个开源云计算平台 Hadoop框架的底层实现部分，适合运行在通用硬件上的分布式文件系统， 具有高容错性， 能提高吞吐量的数据访问，非常适合于大规模数据集上的应用。 

MapReduce在 HDFS的基础上实现的并行框架，为用户提供容易使用的并行编程模式， MapReduce计算包括两个阶段，Map（映射）阶段和 Reduce（规范）阶段。首先， Map 函数把一组 (Key,Value)输入，映射为一组中间结果 (Key,Value) ，然后通过 Reduce函数把具有相同 Key值的中间结果，进行合并化简。 MapReduce将计算作业分成许多小的单元，同时数据也会被 HDFS分为多个 Block ，并且每个数据块被复制多份，保证 系统的可靠性 ， HDFS按照一定的规则将数据块放置在集群中的不同机器上，以便MapReduce在数据宿主机器上进行计算。

 HBase 类似 Bigtable 的分布式数据库，是一个稀疏的，长期存储的，多维的，排序的映射表 . 这张表的索引是行关键字，列关键字和时间戳。所有数据库的更新都是一个时间戳标记， 每个更新都是一个新的版本， 而 HBase会保留一定数量的版本，这个值是可以设定的。客户端可以获取距离某个时间最近的版本，或者一次获取所有版本。

## HDFS数据存储

分布式文件系统 HDFS被设计为将海量文件存储在一个大集群的多台计算机上。HDFS将每一个文件以分块序列的形式进行存储，一个文件的所有分块除去最后一个分块外都是等大小的。 为了实现容错将文件分块进行自动复制。 

文件分块的块大小和复制比例都是可以按照单个文件进行配置的。 

HDFS中的所有文件都是“只写一次”并且严格限定在任何时候只有一个写文件操作者。

HDFS是 Hadoop框架的分布式并行文件系统，是分布式计算的存储基石。

负责数据分布式存储及数据的管理，并能提供高吞吐量的数据访问。 

HDFS的基本特征如下：

(l) 对于整个集群有单一的命名空间。

(2) 文件会被分割成多个文件块，每个文件块被分配存储到数据节点上，而且根据配置会有复制的文件块来保证数据安全性。

(3) 数据一致性。适合一次写入多次读取的模型，客户端在成功创建文件之后，才能看到文件的存在。

(4)Hadoop，包括 HDFS，非常适合在廉价机器上的分布式存储和分布式处理。它是容错的、可伸缩的、非常易于扩展。并且，以简单性和适用性著称的 MapReduce是 Hadoop不可缺少的重要组成部分。

(5)HDFS的默认配置适合于大多数安装的应用。通常情况下，只有在一个非常大规模的集群上才需要修改默认配置。

(6) 支持 shell 命令行风格的 HDFS目录交互。

(7)HDFS是用 java 编写的，可广泛运行在多种软硬件平台上。

(8)HDFS经常性地实现新的特性和改进。

(9)Namenode和 DataNode都内建了 Web服务器，可以方便地查看集群的状态。

 HDFS 的体系框架是 Master/Slave 结构，一个典型的 HDFS通常由单个Namenode和多个 DataNode组成。Namenode是一个中心服务器， 负责文件系统的名字空间的操作，比如打开、关闭、重命名文件或目录，它负责维护文件路径到数据块的映射， 数据块到 DataNode的映射，以及监控 DataNode的心跳和维护数据块副本的个数。集群中的 DataNode一般是一个节点一个，负责管理它所在节点上的存储。 HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。 从内部看， 一个文件其实被分成一个或多个数据块， 这些块存储在一组 DataNode 上。DataNode负责处理文件系统客户端的读写请求。

在 Namenode的统一调度下进行数据块的创建、删除和复制。



HDFS涉及到 Namenode、DataNode和客户端们之间的交互。本质上，客户端与 Namenode通讯是通过获取或者修改文件的元数据，与 DataNode 进行实际的

I/O 操作。如图 13 所示，在 HDFS中有三个重要的角色： Namenode、DataNode和 Client ，其中 Client 就是需要获取分布式文件系统文件的应用程序。

这里通过三个操作来说明他们之间的交互关系：

(l) 文件写入。首先 Client 向 Namenode发起文件写入的请求， Namenode根据文件大小和文件块配置情况， 返回给 Client 它所管理部分 DataNode的信息。Client将文件划分为多个 Block ，根据 DataNode 的地址信息，按顺序写入到每一个DataNode块中。

(2) 文件读取。 Client 向 Namenode发起文件读取的请求， Namenode返回文件存储的 DataNode的信息。 Client 根据返回的信息读取 DataNode上的文件信息。

(3) 文件 Block 复制。Namenode发现部分文件的 Block 不符合最小复制数或者部分 DataNode失效，通知 DataNode相互复制 Block 。DataNode收到通知后开始直接相互复制。

## **HBase**数据存储

HBase – Hadoop Database，是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统， 利用 HBase技术可在廉价 PC Server 上搭建起大规模结构化存储集群。其目的是处理庞大的表，可以用普通的计算机处理 10 亿行数据，并且有数百万列元素组成的数据表这张表的索引是行关键字。 

Hbase可以直接使用本地的文件系统和 Hadoop作为数据存储方式，不过为了提高数据的可靠性和系统的健壮性，发挥 Hbase处理大数据量等功能，需要使用 Hadoop作为文件系统。

### 1、数据模式

 HBase 类似 Bigtable 的分布式数据库， 是一个稀疏的， 长期存储的，多维的，排序的映射表 . 这张表的索引是行关键字，列关键字和时间戳。每个值是一个不解释的字符数组，数据都是字符串，没类型。

用户在表格中存储数据， 每一行都是一个可排序的主键和任意多的列。 

由于是稀疏存储的，所以同一张表里面的每一行数据都可以有截然不同的列。

列名字的格式是 "<family>:<lable>", 都是由字符串组成，每一张表有一个family 集合，这个集合是固定不变的，相当于表的结构，只能通过改变表的结构来改变。但是 lable 值相对于每一行来说都是可以改变的。

HBase把同一个 family 里面的数据存储在同一个目录底下，而 HBase的写操作时锁行的，每一个都是一个原子元素都可以加锁。

所有数据库的更新都是一个时间戳标记， 每个更新都是一个新的版本， 而 HBase会保留一定数量的版本， 这个值是可以设定的。 客户端可以获取距离某个时间最近的版本， 或者一次获取所有版本。

### 2、 概念视图

一个表可以想象成一个大的映射关系，通过主键，或者主键 +时间戳，可以定位一行数据， 由于是稀疏数据， 所以某些列可以是空白的， 下面就是数据的概念视

图：

![image-20210720115134254](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210720115134254.png)

### 3、物理视图

从概念视图看每个表格是有很多行组成， 但是在物理存储上， 它是按照列来保存的。

![image-20210720115206048](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210720115206048.png)

在概念视图上面有些列是空白的，这样的列实际上并不会被存储，当请求这些空白的单元格的时候，会返回 null 值。如果在查询的时候不提供时间戳，那么会返回距离现在最近的那个版本数据。 

因为在存储的时候， 数据会按照时间戳排序。

## **Database**数据存储

数据库（ Database）是存储在一起的相关数据的集合，这些数据是结构化的，无有害的或不必要的冗余，并为多种应用服务；数据的存储独立于使用它的程序；对数据库插入新数据，修改和检索原有数据均能按一种公用的和可控制的方式进行。当某个系统中存在结构上完全分开的若干个数据库时，则该系统包含一个“数据库集合”。

### 数据库中的数据有两种性质：

#### 1、数据整体性

数据库是一个单位或是一个应用领域的通用数据处理系统。数据库中的数据是从全局观点出发建立的，他按一定的数据模型进行组织、描述和存储。其结构基于数据间的自然联系，从而可提供一切必要的存取路径，且数据不再针对某一应用，而是面向全组织，具有整体的结构化特征。

####  2 、数据共享性

数据库中的数据是为众多用户所共享其信息而建立的，已经摆脱了具体程序的限制和制约。不同的用户可以按各自的用法使用数据库中的数据；多个用户可以同时共享数据库中的数据资源，即不同的用户可以同时存取数据库中的同一个数据。数据共享性不仅满足了各用户对信息内容的要求，同时也满足了各用户之间信息通信的要求。

### 数据库的基本结构分为三层：

1. 物理数据层

它是数据库的最内层， 是物理存贮设备上实际存储的数据的集合。 

这些数据是原始数据， 是用户加工的对象， 由内部模式描述的指令操作处理的位串、 字符和字组成。

2. 概念数据层

它是数据库的中间一层， 是数据库的整体逻辑表示。 指出了每个数据的逻辑定义及数据间的逻辑联系， 是存贮记录的集合。 它所涉及的是数据库所有对象的逻辑关系，而不是它们的物理情况，是数据库管理员概念下的数据库。

3. 逻辑数据层

它是用户所看到和使用的数据库， 表示了一个或一些特定用户使用的数据集合，即逻辑记录的集合。

数据库不同层次之间的联系是通过映射进行转换的。

### 主要特点 : 

(1) 实现数据共享。

数据共享包含所有用户可同时存取数据库中的数据， 也包括用户可以用各种方式通过接口使用数据库，并提供数据共享。

(2) 减少数据的冗余度。

同文件系统相比， 由于数据库实现了数据共享， 从而避免了用户各自建立应用文件。减少了大量重复数据，减少了数据冗余，维护了数据的一致性。

(3) 数据的独立性。

数据的独立性包括数据库中数据库的逻辑结构和应用程序相互独立， 也包括数据物理结构的变化不影响数据的逻辑结构。

(4) 数据实现集中控制。

文件管理方式中， 数据处于一种分散的状态， 不同的用户或同一用户在不同处理中其文件之间毫无关系。 利用数据库可对数据进行集中控制和管理， 并通过数据模型表示各种数据的组织以及数据间的联系。

(5) 数据一致性和可维护性，以确保数据的安全性和可靠性。

主要包括：①安全性控制：以防止数据丢失、错误更新和越权使用；②完整性控制：保证数据的正确性、有效性和相容性；③并发控制：使在同一时间周期内，允许对数据实现多路存取， 又能防止用户之间的不正常交互作用； ④故障的发现和恢复： 由数据库管理系统提供一套方法， 可及时发现故障和修复故障， 从而防止数据被破坏

(6) 故障恢复。

由数据库管理系统提供一套方法， 可及时发现故障和修复故障， 从而防止数据被破坏。数据库系统能尽快恢复数据库系统运行时出现的故障， 可能是物理上或是逻辑上的错误。比如对系统的误操作造成的数据错误等。

## 数据存储的可靠性

HBase采用的是 Hadoop作为文件系统，hadoop以机柜为基础的数据存放策略， 那么不仅充分利用了网络宽带，而且提高数据可靠性。 

HDFS的主要目标就是实现在失败情况下的数据存储可靠性。常见的三种失败： Namenode failures, Datanode failures 和网络分割（ network partitions) 。 

### （1）硬盘数据错误、心跳检测和重新复制

每个 Datanode节点都向 Namenode周期性地发送心跳包。 网络切割可能导致一部分 Datanode 跟 Namenode失去联系。 Namenode通过心跳包的缺失检测到这一情况，并将这些 Datanode 标记为 dead，不会将新的 IO 请求发给它们。寄存在 dead Datanode 上的任何数据将不再有效。 

Datanode 的死亡可能引起一些block 的副本数目低于指定值， Namenode不断地跟踪需要复制的 block ，在任何需要的情况下启动复制。在下列情况可能需要重新复制：某个 Datanode 节点失效，某个副本遭到损坏， Datanode 上的硬盘错误，或者文件的 replication 因子增大。

### （2）集群均衡

HDFS支持数据的均衡计划，如果某个 Datanode 节点上的空闲空间低于特定的临界点，那么就会启动一个计划自动地将数据从一个 Datanode 搬移到空闲的Datanode。当对某个文件的请求突然增加， 那么也可能启动一个计划创建该文件新的副本，并分布到集群中以满足应用的要求。这些均衡计划目前还没有实现。

### （3）数据完整性

从某个 Datanode 获取的数据块有可能是损坏的，这个损坏可能是由于Datanode 的存储设备错误、网络错误或者软件 bug 造成的。 HDFS客户端软件实现了 HDFS文件内容的校验和。 当某个客户端创建一个新的 HDFS文件，会计算这个文件每个 block 的校验和，并作为一个单独的隐藏文件保存这些校验和在同一个 HDFS namespace下。当客户端检索文件内容，它会确认从 Datanode 获取的数据跟相应的校验和文件中的校验和是否匹配， 如果不匹配， 客户端可以选择从其他 Datanode 获取该 block 的副本。

### （4）元数据磁盘错误

FsImage和 Editlog 是 HDFS的核心数据结构。这些文件如果损坏了，整个 HDFS实例都将失效。因而， Namenode可以配置成支持维护多个 FsImage 和 Editlog的拷贝。任何对 FsImage或者 Editlog 的修改，都将同步到它们的副本上。 这个同步操作可能会降低 Namenode每秒能支持处理的 namespace事务。这个代价是

可以接受的， 因为 HDFS是数据密集的， 而非元数据密集。 当 Namenode重启的时候，它总是选取最近的一致的 FsImage和 Editlog 使用。Namenode在 HDFS是单点存在，如果 Namenode所在的机器错误， 手工的干预是必须的。目前，在另一台机器上重启因故障而停止服务的 Namenode这个功能还

## 数据压缩

### （1）HDFS数据压缩与组织方法

任何一种数据资源都具有生命周期， 不同的时期有其存在的不同意义。 在数据刚生成的数日内，访问频率最高，带来的使用价值也最高。随着时间推移，访问频率会逐渐降低， 数据的价值也随之下降， 低访问频率的数据量远远超过高访问频率的数据量。 不同生命周期的数据是提供给不同使用对象的， 这就为以最低的成本获得最高的使用价值提供了可能。

通常情况下，某段时间内访问量比较大的数据只有不到 20%，80%的数据是不经常被访问的， 虽然这些数据访问量低， 但这些数据仍然很重要， 必须完好的保存。同时考虑到方便数据压缩， 这里采用了分级存储策略， 这样不仅可以方便为访问量大的数据项设置缓存，而且为数据压缩提供了方便，显著提高了效率。

分级存储就是以信息生命周期管理理论为依据， 根据数据所能提供的使用价值来决定存储成本、存储设备。文件依据用户需求有选择地对某些数据进行迁移，如进行远端备份等。 数据分级存储之所以重要， 是因为它既能最大限度地满足变化的需求，又能方便文件的组织和压缩。 数据分级存储的优点有减少总体存储成本、性能优化、改善数据可用性、数据迁移对应用透明。借助云平台，分级存储满足以下要求： 数据的安全性、 数据的高可用性、 容量可扩展性、 设备的兼容性、管理的高效性、经济效益性。

数据将被组织成两级，一级称为 chuck，一级称为 block 。chuck 被分为多个 block ，文件将以 block 的形式存储在数据服务器上。 block 的优点是方便文件压缩和文件的传输， 适合多种备份方式， 在很大程度上提高了存储效率和可扩展性。下图给出了基于分级存储的数据块级压缩方式。

![image-20210720115612247](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210720115612247.png)

处理流程如下：

1）将一个 chunk 划分成为多个 block 。 

2）读取一个 block ，对该 block 进行数据压缩并写入到临时缓存中。

3）将临时缓存的压缩数据拷贝到缓冲池中。

4）重复 2-3 步直到一个 chunk 中的 block 都被压缩拷贝完成。

5）将缓冲池中的内容按顺序回写到存储区域。



# 数据实时处理、实时查询系统

数据处理是对数据的采集、 存储、检索、加工、变换和传输。 数据是对事实、概念或指令的一种表达形式， 可由人工或自动化装置进行处理。 数据的形式可以是数字、文字、图形或声音等。数据经过解释并赋予一定的意义之后，便成为信息。数据处理的基本目的是从大量的、 可能是杂乱无章的、 难以理解的数据中抽取并推导出对于某些特定的人们来说是有价值、 有意义的数据。 数据处理是系统工程和自动控制的基本环节。数据处理贯穿于社会生产和社会生活的各个领域。

数据处理技术的发展及其应用的广度和深度，极大地影响着人类社会发展的进程。

## 数据立方 **(DataCube)** 

我们以 B+树的结构建立了字段的索引，每个 B+树结构的字段索引相当于一个数据平面，这样一个全局数据表与其多个重要字段的索引就组成了一个类似于立方体的数据组织结构，我们称之为“数据立方 (DataCube)”。如下图所示：

![image-20210720115712607](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210720115712607.png)

数据立方 (DataCube)是一种用于数据分析与索引的技术架构。它是针对大数据(big data) 的分布式数据库，可以对元数据进行任意多关键字实时索引。通过数据立方对元数据进行分析之后，可以大大加快数据的查询和检索效率。

数据立方是凌驾于数据存储层和数据库系统之上的，通过数据立方解析后，可以大大增加数据查询和检索等业务， 可以让系统平台具备数据实时入库、 实时查询、查询结果实时传输等优势。

## 任务调度器（ **JobKeeper**）

JobKeeper 调度平台是建立于虚拟化资源层之上，统一调度，统一配置的管理平台，用于对集群中任务实时的处理调度， 实时结果集的反馈， 集群的负载均衡，失败调度，集中管理，集中配置的平台。 用来保证整个集群的超低人员干预。

同时，提供完善的集群伸缩机制为整个服务提供更高的可靠性。

JobKeeper 云调度技术架构图

![image-20210720115744801](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210720115744801.png)

应用层是一组用于管理和结果反馈的显示组件。用于显示任务的处理情况以及集群中机器的活动情况， 同时其也是一个上层应用和底层服务的对接平台。 是整个系统面向用户和开发人员的基础承载。

业务层是对于应用层的相关功能的业务化， 数字化处理，用于将应用层的需求任务进行规则化划分，形成统一的处理化模式。

数据处理层是独立的数据处理程序， 是对不同需求数据的统一处理方案， 他的运行与监控的工作将由 JobKeeper 调度平台进行统一的配置管理。

存储层是用来存储数据存储层的处理结果集或者其他中间结果集的单元。

虚拟化资源层是将实体的机器进行虚拟化，形成更大范围的服务集群。

JobKeeper 调度平台是由一组管理节点 （Master Node）和一组处理节点（Task Node）组成，管理节点组是一组基于 Webserver 的 RPC(RPC采用客户机 / 服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程， 然后等待应答信息。 

在服务器端，进程保持睡眠状态直到调用信息的到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最

后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 

服务器，负责对处理节点的系统信息以及任务处理信息进行实时的跟踪和保存，对应的信息镜像存储在基于 cStor 或者 NFS服务的存储系统上， 保证每个管理节

点中的镜像信息的 实 时同步 。 同时架 设在管理节 点上的 ZooKeeper 服务(ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，包含一个

简单的原语集。分布式应用可以使用它来实现诸如：统一命名服务、配置管理、分布式锁服务、集群管理等功能。) 用于对整个管理节点组进行统一的配置化管

理。处理节点组通过 RPC的远程调用获取各自节点的任务处理目标， 并实时的和处理节点上的任务处理目标进行对比，控制程序的执行和结束。 

（注：这里的程序，可以是任何语言任何形式的独立程序， 但是必须提供执行脚本， 和运行参数选项）处理节点组会在一个设定的心跳间隔内主动的和管理节点组联系一次， 报告节点存活状态。如果在若干个心跳间隔后管理节点组仍然没有获取到处理节点心跳报告，那么该处理节点将会被踢出处理节点组， 同时该节点处理的所有处理任务也会被重新调度。 随着集群处理数据量的不断增大， 处理节点组提供了简单高效的自动化部署方案， 当新机器加入处理集群后， 会主动的与管理节点组同步心跳信息，从同一配置服务器 ZooKeeper上获取相关配置信息，通过 WebServer服务获取任务列表，开始执行数据处理工作。

JobKeeper 调度平台提供了一套基于 Web的管理化界面， 可以实时的观察各个处理节点的任务运行状态， 以及任务列表的分配情况， 机器的负载情况等。 用户在管理系统界面上可以完成所有的工作， 如新任务的添加， 任务的手动调度以及集群日志的查看与分析等。

任务处理节点和管理节点之间维护一个心跳时间， 实时向管理节点汇报任务处理信息，同时，任务处理节点在每个心跳时间内向管理节点获取该处理的任务列表，并和本机正在处理的任务列表进行比对， 完成相关的任务调度工作。 若一个处理节点在多个心跳时间范围内仍然没有主动的和管理节点相互联系， 那么管理节点将会根据各机器的负载情况， 将失去心跳连接的处理节点上的任务进行任务的重新分配和执行。