# 面向车路协同的路侧感知仿真系统

PDF文档地址：http://c-s-a.org.cn/csa/article/pdf/7907?st=article_issue

智能交通系统(Intelligent Transport System, ITS)通过人工智能与信息通讯技术可以有效提升道路交通的安全和效率[1,2], 目前已经得到广泛的认可, 它包含“聪明的车”和“智慧的路”两部分. 车路协同是ITS发展的高级阶段, 用来实现车与车以及车与路侧系统之间的通信, 使车辆能够更好地感知周围环境, 接受辅助驾驶的相关信息, 让道路监管部门能够更有效地处理交通事故[3,4].

其中, 路侧感知是车路协同应用开发的重要组成部分, 通过在路侧部署传感器, 将采集到的路面信息经V2X通信给到车辆, 使车辆拥有超视距的感知能力. 在实际应用中, 为达到最优的路侧感知效果, 不同的场景往往需要不同的RSU配置, RSU的选型及安装是一个耗时耗力的过程, 另外, 交通参与者的识别是路侧感知的核心, 基于机器学习的识别算法需要大量的标签数据, 而人工打标签被验证是一个效率极其低下的方式.而随着近些年计算机硬件性能的不断提升, 将仿真技术应用于智能交通领域成为了各类研发机构加速开发进程的必要手段[5,6].

当前<font color='red'>智能交通领域的模拟仿真主要围绕自动驾驶算法验证, 车路协同V2X通讯, 车载传感器数据采集</font>等几个方面展开。

Gelbal等基于dSPACE Scalexio系统和Carsim仿真软件构建了一套用于自动驾驶算法开发的硬件在环模拟仿真系统[7], Amini等提出了一种基于虚拟图像合成和变换, 以数据为驱动的仿真工具, 用于端到端的自动驾驶控制策略研究[8], Szendrei等基于SUMO设计了一套用于车路协同应用快速建模和测试的硬件在环V2X模拟仿真架构[9], Choudhury等搭建了集成VISSIM、Matlab和NS3, 用于V2X协议和应用的模拟仿真测试环境[10], Su等提出了一种采用GPU计算虚拟环境中三维物体点云的车载激光雷达仿真方法[11], 百度采用真实点云背景结合虚拟交通体的方式来模拟车载激光雷达感知虚拟环境的方式[12],Dworak等则利用CARLA仿真软件模拟激光雷达采集纯虚拟的点云数据, 通过与公开测试集中的数据对比, 发现仿真环境中的模拟点云可以作为真实数据的补充[13].

从分析来看, 针对路侧感知的模拟仿真目前还很少人涉及, 但作为车路协同的应用开发却同样是不可或缺的, 本文将从路侧感知的模拟仿真入手, 介绍相关的系统搭建工作以及在此基础上的两个应用案例.

# 1   仿真系统架构

<font color='red'>经典的自动驾驶仿真平台包括虚拟场景、动态案例仿真、传感器仿真、车辆动力学仿真等独立模块</font>[14],如图1所示. <font color='red'>针对路侧感知的模拟仿真侧重于路侧传感器与车辆以及环境之间的交互, 因此, 跟自动驾驶仿真平台的最大区别在于传感器类型为路侧传感器而非车载传感器, 但为了最大限度还原真实世界的相关特性, 仍然需要包括图形引擎、物理引擎以及与外界通讯的中间件系统作为基础支撑</font>, 如图2所示

![image-20210709141825258](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709141825258.png)

文献[15]从V2X、交通流、非自动驾驶车辆、传感器、图形渲染、自动驾驶车辆动态模型等几方面总结了当前用于智能交通领域的主流模拟仿真软件情况, 如表1所示. 其中, TF代表交通流, DM代表非自动驾驶车辆的驾驶模型, SE代表传感器, VI代表渲染画质, VD代表自动驾驶车辆动态模型. 另外, 表格内, i表示需要二次开发, o表示没有相关功能, – –表示非常差,– 表示较差, +表示较好, ++表示非常好.

![image-20210709141943637](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709141943637.png)

由图2可知, 本文设计的路侧感知仿真系统需要突出包括传感器仿真, 环境和交通渲染, 车辆动力学模拟等, 通过表1的数据分析可以得到满足这些要求的有Carla、LGSVL、Righthook、SCANeR、VTD以及CarMaker, 其中Carla和LGSVL为开源软件.

LGSVL是基于游戏引擎Unity开发的一款主要用于自动驾驶开发和测试的模拟仿真软件, 它支持包括仿真环境、传感器以及通讯内容的自定义, 图3为LGSVL的工作流程[16], 本文将基于LGSVL开发适用于路侧感知的仿真系统. 其中, 利用自定义场景功能开发适用于路侧感知的模拟环境, 利用自定义车辆及传感器模型功能创建路侧感知单元, 利用自定义通讯内容实现路侧感知数据的采集与传输.

![image-20210709142014187](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142014187.png)

# 2   模拟场景构建

确定模拟场景是仿真测试的前提, 本文模拟的场景为所在团队进行无人驾驶的车辆测试场, 图4为其平面示意图, 其中由正门通往东门的L型主干道及其周边为本次重点模拟区域. 路侧感知仿真系统的模拟场景构建内容包括静态环境、动态交通、路侧单元等,模拟场景的构建手段通常包括基于建模软件构建场景,基于已经完成的游戏搭建场景, 基于增强现实方法构建场景, 基于高精地图生成场景等方式, 本文采用基于建模软件构建虚拟场景, 建模软件为开源3D建模软件blender[17].

![image-20210709142030260](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142030260.png)

## 2.1   静态环境静态环境

主要包括用于车辆行驶的车道, 场景内的建筑, 区域内的绿植、路灯等, 这些构成了模拟场景的客观环境, 并且不随仿真测试过程中其它条件的变化而改变, 通过blender建模后经Unity高清渲染后得到本次模拟仿真系统的静态环境如图5所示.

![image-20210709142044907](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142044907.png)

## 2.2   动态交通

<font color='red'>动态交通是仿真测试场景的关键组成, 主要指仿真中具备动态特性的管控、车流、人流等部分, 包括红绿灯仿真, 机动车仿真, 行人仿真等</font>. 动态交通仿真场景构建方法主要有<font color='red'>基于真实交通案例数据的构建,基于真实案例数据的泛化构建, 以及基于微观交通仿真系统的构建. LGSVL通过微观仿真方法构建动态交通, 内置地图标注工具用来完成三维环境中高清地图的创建, 基于高清地图实现车辆按照车道行驶, 遵循交通信号灯, 限速, 交叉口决策等功能</font>. 图6为在行驶车道上进行地图标注.

![image-20210709142106478](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142106478.png)

LGSVL内置丰富的车辆模型, 包括两厢车, 三厢车, SUV, 吉普车, 卡车, 校车等, 通过组合不同的颜色外观, 可以产生数十种车辆模型, 基本涵盖了路面上常见的车辆种类. 同时, LGSVL支持更多类型车辆的自定义与创建. 图7为在静态环境中添加车辆模型后的效果.

![image-20210709142121547](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142121547.png)

## 2.3   路侧单元

路侧单元是车路协同的核心部件, 负责车路信息的采集、处理与传输, 也是本文提出的面向车路协同的路侧感知仿真系统的重点研究对象. LGSVL作为一款主要面向自动驾驶的仿真软件, 本身并不具备路侧单元这一组成类型, 但是LGSVL支持车辆及传感器模型的高度自定义, 本文即利用LGSVL的该功能进行面向车路协同的路侧感知单元的新建.

常见路侧单元包括摄像头、激光雷达、毫米波雷达、工控机等, 本文根据园区内实际情况, 将路侧单元与太阳能路灯结合, 在blender中构建路侧单元三维模型如图8(a)所示, 在LGSVL中, 通过与新建车辆模型相同的方法得到路侧单元对应的可加载资源, 最终在LGSVL中加载路侧单元并配置相应的传感器参数后如图8(b)所示.

![image-20210709142152238](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142152238.png)

# 3   数据采集与处理

数据采集是路侧传感器的本质用途, 根据传感器类型不同, 数据采集的内容及处理方式也不一样, 如<font color='red'>摄像头采集的是图像信息, 而激光雷达采集的则是三维点云数据</font>. 由于激光雷达的成本较高, 且三维数据的后期处理较为复杂, 运用仿真手段实现激光雷达的物理特性模拟以及对应数据收集和处理已然成为了真实路测的重要补充. 本文以路侧激光雷达为例介绍其仿真数据的生成及处理和输出过程.

## 3.1   模拟点云数据生成

激光雷达仿真的思路是参照真实激光雷达的扫描方式, 模拟每一条真实雷达射线的发射, 通过与场景中所有物体求交, 若在激光雷达的最大探测距离内存在交点, 则返回相应的点云坐标. 假设模拟激光雷达为L线, 水平分辨率为R, 水平扫描范围为360°, 得到每一帧发射射线的数量N为:

![image-20210709142218324](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142218324.png)

由式(1)和图9可知, 当激光雷达频率较高, 场景内环境较为复杂且模型足够精细时, 通过模拟射线求交的计算量极大, 以激光雷达为64线, 水平分辨率0.4°,频率10 Hz为例, 单纯每秒发射的激光雷达射线就高达576000条, 在此基础上还需要对每一条射线遍历场景内除激光雷达外的所有物体模型. 为了达到实时仿真的效果, 可以运用CPU并行或GPU计算的方式来提高计算效率, LGSVL采用GPU计算点云数据.

真实点云数据除了位置坐标外, 还有一个关键信息是反射强度, 反射强度主要反映的是不同物理材质对激光雷达所使用的近红外光线的反射率. 因此, 模拟点云数据同样需要考虑强度值, LGSVL中通过获取模型材质中的金属度及颜色值并进行归一化处理得到取值范围在0~255间的强度值.

## 3.2   真值数据生成与处理

有了模拟点云数据后, 一般还需要配合真值数据,用作模型识别训练的数据集. 真值数据对应真实数据中的人工标签数据, 数据内容包括可识别物体的位置、朝向、包围盒大小、速度、类型等, 不同于人工打标签的过程, 真值数据相对于仿真系统而言是已知的, 只需要将真值数据与点云数据进行配合同步输出即可,因此可以大大提高输出标签的效率. 在LGSVL中新建真值数据传感器, 数据类型为Detected3DObject, 如图9所示, 其中, Id为同一帧数据内识别物体的序列, Label为物体标签, Position为物体位置, Rotation为物体朝向, Scale为物体包围盒尺寸, LinearVelocity和AngularVelocity分别为物体线速度和角速度. 为实现真值数据与点云数据匹配, 需要将真值数据传感器与激光雷达传感器的配置参数保持一致, 如位置姿态、有效范围、频率等.

Unity中, 姿态角采用四元素表示, 如图10中的Rotation值, 同时坐标系的表示为左手系, 而一般用于模型训练的标签数据采用右手坐标系下的欧拉角表示.欧拉角有12种表示, 分别代表着12种旋转次序[18], 本文采用ZYX的旋转次序. 假设Unity中四元素姿态角表示为quaternion=(x, y, z, w), 对应ZYX欧拉角为euler=(roll, pitch, yaw), 则两者之间存在关系:

![image-20210709142258140](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142258140.png)

## 3.3   仿真数据输出

LGSVL支持包括ROS, ROS2, CyberRT等多种通信方式, 本文采用基于Rosbridge的通讯实现模拟点云数据与真值数据的输出. Rosbridge为非ROS程序提供了一个使用ROS功能的JSON API, 用于向ROS发送基于JSON的命令的规范[19]. Rosbridge包含一个WebSocket服务器, 用于与Web浏览器进行交互, 仿真系统与ROS之间的通信如图11所示.

![image-20210709142319429](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142319429.png)

由于模拟点云数据与真值数据分别通过不同的传感器采集, 为了实现每一帧文件的相互匹配, 本文采用获取当前ROS时间作为每一帧点云数据和真值数据的命名, 如当前ROS时间为n.ms, 对应时刻采集的点云数据文件保存为nm.pcd, 真值数据文件为nm.txt. 将同一帧的模拟点云数据与真值数据导入Rviz中显示如图12所示.

![image-20210709142332051](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142332051.png)

# 4   实验

## 4.1   激光雷达安装高度分析

在现实中, 由于激光雷达成本较高, 在路侧布局中需要优化激光雷达的布局使得单个激光雷达的有效覆盖区域尽可能多地被利用. 对于只有单侧布置RSU的路面, 因为各类车辆的形体差异较大, 有可能存在小车被大车遮挡的情况, 从而对车路协同提供的超视距功能构成挑战, 为了减少这种因大车遮蔽造成激光雷达盲区的情况, 最简单有效的方法是增加激光雷达的安装高度. 获取激光雷达的最低安装高度需要综合包括激光雷达参数, 道路环境参数, 车辆参数等多种条件进行测试, 通过真实路测是不大现实的, 而借助本文提出的路侧感知仿真系统可以简单直观地完成. 实验中, 选取线数为16线, 垂直角度为30°, 有效距离为120 m的激光雷达, 大车的长度为10.5 m, 高度4.4 m, 小车长度4.6 m, 高度1.4 m, 通过改变激光雷达高度和倾角值, 获得6组激光雷达在仿真环境中的点云覆盖情况如图13所示, 从图中可知, 随着激光雷达高度增高, 小车被点云覆盖的可能性越大, 同时为了使得点云覆盖车道的大部分, 倾斜角度也需要增大, 当激光雷达高度为10米, 倾斜角度为55°时, 小车可以有较好的点云覆盖.

![image-20210709142357883](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142357883.png)

## 4.2   基于模拟点云数据的车辆识别

相对于基于摄像头采集的二维图像识别物体, 基于激光雷达的点云数据的物体识别因为不受环境光的影响, 具有更高的鲁棒性, 因此在车路协同中具有重要的地位. 相应地, 由于单帧的点云数据量巨大, 同样采用深度学习的方法, 基于点云的识别难度较于图像识别有过之而无不及, 尤其制作标签数据的过程, 采用人工的方式是极其困难的. 通过仿真系统可以快速准确地生成大量标签数据, 但模拟数据是否可以替代真实数据仍需要通过实验进行验证.

本文设计了4组实验进行验证, 第1组采用真实数据训练真实数据测试, 第2组采用模拟数据训练模拟数据测试, 第3组采用真实数据训练模拟数据测试,第4组采用模拟数据训练真实数据测试, 4组实验采用相同的训练网络, 训练集与测试集的数据量均按4:1得到, 最后结果如表2所示.

![image-20210709142423884](https://gitee.com/AiShiYuShiJiePingXing/img/raw/master/img/image-20210709142423884.png)

其中, Precision为识别的精确率, 相对于测试集中检测出来的样本而言, Recall为召回率, 相对于整个测试集而言, F1 score为精确率和召回率的调和平均数.从表2中可以看出, 不管是用真实数据测试模拟数据,还是模拟数据测试真实数据, 最后的结果都显示各类评价指标可以比较接近纯真实数据的情况, 由此可知,通过仿真系统输出的模拟点云数据可以较好地还原真实数据的特征.

# 5   结论

随着智能交通领域的快速发展, 模拟仿真技术在其中扮演着越来越重要的角色, 尤其是针对自动驾驶和车路协同已经有很多的仿真应用和研究, 然而面向路侧感知的仿真仍然鲜有人涉足. 本文提出了一种面向车路协同的路侧感知仿真系统, 系统基于自动驾驶仿真软件LGSVL进行二次开发构建, 开发内容包括模拟仿真环境, 路侧单元及数据采集与通讯, 最后通过两个实验对仿真系统的应用进行说明. 实验一借助仿真环境分析了激光雷达的高度与路面点云覆盖之间的关系, 可以为激光雷达的实际安装位置提供参考, 实验二通过对比由仿真环境中输出的点云数据得到的车辆识别模型与由真实数据得到的模型之间的相互验证结果,得出本文设计的仿真系统的对激光雷达和环境的模拟可以较高程度地还原真实情况.

另外, 在本次的研究中, 由于将激光雷达传感器与真值数据传感器作为单独的个体进行考虑, 存在无法在时间上做到完全同步的问题, 会导致真值数据和点云数据在空间上存在细微的差距, 其次, 本文实验中仿真环境和真实环境仍存在一定的差异, 如绿植、车棚等, 导致实验二中交叉验证出现各项指标略低于自身验证的情况, 这些将在后续的研究中进行重点考虑. 同时, 探索路侧感知仿真系统在车路协同中更多的应用场景也是未来研究的方向.