- [智能网联汽车——智能化](https://blog.csdn.net/weixin_42146017/article/details/103872188)

### 一、无人驾驶的系统组成

![1.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9jZGI5YzAzOTZjNTQ5OWViNzczZGQ4ZTJhZTcxZTA4ZS5qcGc?x-oss-process=image/format,png)

- 算法端包括面向传感、感知和决策等关键步骤的算法，从传感器原始数据中提取有意义的信息以了解周遭的环境情况，并且根据环境变化做出决策；
- 客户端包括机器人操作系统以及硬件平台，融合多种算法以满足实时性与可靠性的要求；
- 云端包括数据存储、仿真、高精度地图以及深度学习训练模型，为无人车提供离线计算以及存储的功能，通过云平台我们能够测试新的算法，更新高精度地图，并且训练更加有效地识别跟踪和决策模型。

### 二、无人驾驶的感知

#### 1.常用的传感器

##### 1.1回顾

前面在[智能网联汽车——传感器与驾驶辅助](https://mp.weixin.qq.com/s?__biz=MzU4OTQ2MDc4OA==&mid=2247484076&idx=1&sn=74ef953ea828c2fd9974d8320350e16e&chksm=fdcc66f7cabbefe1e151c78b7a89ac461188371be07e2a70b89c23447b97047a4b7fab33548c&token=863619132&lang=zh_CN#rd)一文已经详细介绍了各类传感器，现在再简单回忆一下无人驾驶车辆的传感器种类，

![无人驾驶车辆传感器.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC85MGI1ZDQyZDZjMDMyNDhkMzI4ZDZhMjllMjQ3MzcxZS5qcGc?x-oss-process=image/format,png)

并对比一下主要传感器的优缺点。

![10.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC83Y2IwNDVmOGM0ZTU1ZjgyOGM5YTA3YWZlMzY1MGViNy5wbmc?x-oss-process=image/format,png)

##### 1.2无人车传感器的布设

在实际的具备自动驾驶功能的车辆上，同时安装有激光雷达、毫米波雷达、视觉等传感器，并且数量可能不止一个。

**1）谷歌**：无论是在白天还是夜晚，都能实行360°监控，视野面积可达3个足球场。

![12.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9hNmE3NjFkZWVkNTNjYzQ1YTIxYjc2NDVkNzc3Zjk5ZC5wbmc?x-oss-process=image/format,png)

激光雷达系统：高频率的短程激光雷达;高分辨率的中程激光雷达;长距离激光雷达。

![Snipaste_2019-12-12_20-00-02.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC82MmQ3Njk2MmJjOTkxZTMwZGMwMzk1YzJkNDQzMGVhNC5wbmc?x-oss-process=image/format,png)

视觉传感器系统:配备了8个镜头,具有360°视野,在长距离、日光和低亮度的情况下
 也能很好地工作。

![Snipaste_2019-12-12_20-00-16.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9hNjg4ZjQxN2I0OTUyMjk1MmE0ODZiNzc3MDE0OGEzYS5wbmc?x-oss-process=image/format,png)

**2）奥迪**：2017年7月,奥迪在其全球品牌峰会上,正式对外发布了第五代奥迪A8,这款车型搭载了奥迪的L3高度自动驾驶功能,且是全球首款搭载L3高度自动驾驶系统的量产车型。据介
 绍,全新奥迪A8的高度自动驾驶功能,拥有“拥堵路段自动驾驶”、“泊车自动驾驶”
 和“车库自动驾驶”等功能系统。

![Snipaste_2019-12-12_20-03-57.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC84MThlODczOTBmZjM3YjNlNmE0ZGNkYjcyNWY1ZDgyZC5wbmc?x-oss-process=image/format,png)

通过所有组件收集大量冗余信息,可以让监测更准确。即使一个信息源或者多个信息源的数据缺失,汽车可以照常自动行驶。

**3）德尔福**：2017GES上,德尔福( DELPH)与Mob i leye共同展示中央传感定位与规划
  (CSLP)自动驾驶解决方案,并在复杂路段(包含信号不佳的隧道)跑上10km。该方案总共包括:7个视觉传感器、8个毫米波雷达、5个激光雷达,改善了车辆在隧道或信号不佳的路段的定位能力,即便汽车在丧失GPS信号与云端地图信号的糟糕环境下,CSLP自动驾驶系统依旧能确保10cm以内的定位精度。

![Snipaste_2019-12-12_20-06-29.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9lZmFlYzYyMzQ3ZGUxODhiYjc2MjBlY2JjODMzN2MzNC5wbmc?x-oss-process=image/format,png)

同时我们应该注意到对于低级别的自动驾驶车辆，即具备驾驶辅助功能的车辆，其传感器的布局及数量也不尽相同。

**4）0级无人驾驶**：又称为“非自动驾驶”,由**人类驾驶员**时刻完全地控制汽车的所有底
 层结构,包括加减速、转向等。

![Snipaste_2019-12-12_20-07-50.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9lMGU3MjQyZTI0MTY4YmJjYjQ2MzY5NDljZjA2M2FmYS5wbmc?x-oss-process=image/format,png)

0级无人驾驶车辆可能会在**前后方**布置毫米波雷达、视觉传感器、超声波传
 感器等传感器,主要用于防碰撞提示、帮助驾驶员观察环境。

**5）1级无人驾驶**：又称为“辅助驾驶”,在特定驾驶模式下由辅助驾驶系统根据环境信
 息**控制转向或加减速中的一种**,而其它驾驶任务由人类驾驶员完成。

![Snipaste_2019-12-12_20-10-00.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC85NGU3Nzg3MjViNzMzOTEwOGIxMWYyYmU5YjgyMjdjMy5wbmc?x-oss-process=image/format,png)

1级无人驾驶车辆会在**前后方**布置毫米波雷达、视觉传感器、超声波传感器等传感器,在**內部**布置视觉传感器,以获取大范围内行驶路径上的障碍物信息,实现车道保持、紧急自动刹车、驾驶员疲劳探测等功能。

**6）2级无人驾驶**：又称为“部分自动化”,在特定驾驶模式下由自动驾驶系统根据环境信息**同时控制转向和加减速**,而其它驾驶任务由人类驾驶员完成;

![Snipaste_2019-12-12_20-15-00.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC85ODA5OTNmNTRmY2ZhOTg2YWVhNmY2NzMxZWMzZGExMy5wbmc?x-oss-process=image/format,png)

2级无人驾驶车辆会在**前后方和四周**布置毫米波雷达、视觉传感器、超声波传感器等传感器,在**内部**布置视觉传感器,以获取大范围内行驶路径上以及车辆周围的障碍物信息,实现自适应巡航、自动泊车、自动换道等功能。

**7）3~5级无人驾驶**：车辆的传感器配置大致相同,主要区别在于对数据的处理以及驾
 驶行为决策的成熟度。

#### 2.环境感知技术

![6.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9jY2RmNzJlMGU2ZTM5NmE3YTQ5YWZlYmQ3Yjc0NDg2Ny5qcGc?x-oss-process=image/format,png)

##### 2.1车道线

传统的方法就是使用**基于特征检测**的**霍夫变换**从黑白的图像当中去检测直线或者线段。基本流程如下：

- 读图,或者读视频
- 选取关键兴趣区域,减少计算量
- 取图,灰度化
- 高斯平滑,减少边缘干扰
- 利用cany算子,进行边缘检测
- 集中到边缘检测的兴趣区域,进一步减少运算量
- 利用霍夫变换变换,进行直线检测
- 将检测出来的直线与原图进行合成

![7.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC82YmVjNDVjOGFkNDhiNGM5MjY1OWRlOGUyOGE3Yjg2ZC5qcGc?x-oss-process=image/format,png)

这种方法存在一些弊端：

- 没有学习过程,对变化没有适应性(虽然减少了样本标注的过程)
- 兴趣区域(ROI)固定,没有适应性,取决于摄像机、车辆相对于道路的位置
- 各种国像处理过程的参数、阈值等需要提前设定,调整不灵活。
- 处理速度慢,4.5-6帧/秒,正常读取速录为30帧/秒。

故现在更多的是使用**基于深度学习**的目标检测方法，关于深度学习及其使用将在后面的《深度学习与无人驾驶》推送中专门介绍。

下图就是使用基于深度学习的方法检测出的车道线。

![UTOOLS1576153815714.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC84YzcxMzBjZTRjMTk2YzFjNGViZjg0Nzg4ZDJkYzQ0Zi5wbmc?x-oss-process=image/format,png)

其他的车辆、红绿灯、交通标志都可以使用基于特征检测的方法以及基于深度学习的方法。

#### 3.定位

##### 3.1GPS

**组成：**

![14.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC83YmZkNmQwODYwMmE3MTUzZWY2YTY4YjRiODg5MWExMC5wbmc?x-oss-process=image/format,png)

**缺点：**

- 在高楼中由于高楼遮挡容易丢失信号
- 传播受大气电离层的反射，云层的反射和折射影响，会导致定位误差
- 更新频率（10Hz）不高

##### 3.2IMU

**概念**：IMU( Inertial Measurement Unit,惯性测量单元)是测量物体的角速度和
 加速度的装置,进而可以推算物体的姿态、速度和位移。

**优缺点：**

- 无信号丢失等问题。
- 全自主式、全天候、不受外界环境的干扰影响。
- 频率比较高。
- 但存在误差积累，在长时间距离内并不能保证位置更新的准确性

##### 3.3 GPS/IMU定位融合

**原因：**

- GPS是一种相对精准的定位传感器,但更新频率低,并不能满足实时计算的要求。
- 惯性传感器的定位误差会随着运行时间增长,但由于其是高频传感器,在短时间内可以提供稳定的实时位置更新。
- 通过融合这两种传感器的优点,各取所长,就可以得到比较实时与精准的
   定位。

**实现：**

![UTOOLS1575548529485.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9hMjYwMzdhZDhlYjlkMmYyZTdiNDZhNTA2MjhmMzMzYS5wbmc?x-oss-process=image/format,png)

**卡尔曼滤波：**

1. 功能:从一组有限的、包含噪声的对物体位置的观测序列预测出物体的位置坐标及速度。
2. 架构:

- 预测阶段:基于上一时间点的位置预测当前时间点的位置。
- 更新阶段:通过当前对物体位置的观测去纠正位置预测、从而更新物体的位置

**融合优势：**

- 当GPS信号受到遮挡、高强度干扰或当卫星系统接收机出现故障时,INS可以独立地进行导航定位。
- 提高定位频率。
- GPS信息可以用来修正INS的输出信息,控制其误差随时间的积累

##### 3.4 RTK GPS/IMU定位融合

为了降低天气、云层对GPS信号的影响，出现了其他GPS技术，如差分GPS。这种技术通过在一个精确的已知位置（基准站）上安装上安装GPS检测接收机，计算得到基准站与GPS卫星的距离，然后根据误差修正结果，从而提高了定位精度。

差分GPS分为位置差分和距离差分，距离差分又分为伪距差分和载波相位差分。RTK（Real-Time  Kinematic，实时动态）技术即载波相位差分，可使定位精度达到cm级别，这也是很多无人驾驶公司采用RTK技术定位的原因，但由于硬件成本极高，采用RTK定位技术实现大规模量产商用的可行性不高，并且仍然受城市建筑物影响，楼群越密集越高，定位误差越大。

##### 3.5基于激光雷达的SLAM定位

**SLAM（即时定位与地图构建）**：机器人在未知环境中从一个未知位置开始移动，在移动过程中根据位置估计和地图进行自身定位，同时在自身定位基础上构建增量式地图，实现机器人的自主定位和导航。扫地机器人应用的原理就是SLAM。

**激光SLAM**：3D激光雷达采集到的物体信息呈现出一系列分散的、具有准确角度和距离信息的点，被称为点云。通常，激光SLAM系统通过对不同时刻两片点云的匹配与比对来计算激光雷达相对运动的距离和姿态的改变，从而完成对机器人自身的定位。

![14.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC8xOWYxMzc3YzRlNTliNTQzMDQ3MDk2MzEwMjQxMThlZS5qcGc?x-oss-process=image/format,png)

**优缺点：**

- 稳定
- 数据量少
- 定位及地图创建精度高
- 但传感器昂贵，量产商用可行性低

##### 3.6基于视觉的SLAM定位

**优缺点：**

- 获取数据成本低
- 数据量丰富
- 建图精度略低
- 受光线、环境影响较大

结合之前的介绍，视觉传感器分为单目和双目，故也有单目、双目SLAM之分。从可靠性和鲁棒性来说，双目要比单目SLAM更好一些。

一般来说，视觉SLAM都结合IMU等传感器使用，以更大程度地提高建图精度和姿态估计精度。

近几年随着深度学习、人工智能技术的发展，在SLAM领域也有一些结合AI、深度学习、目标检测、语义分割等技术的SLAM技术出现，如语义SLAM等。通过这些方法可以从图像中获得更丰富的语义信息，这些语义信息可以辅助推断几何信息，如已知物体的尺寸就是一个重要的几何线索。

#### 4.高精度地图

SLAM主要适用于机器人等领域。在诸如无人清洁车、低速园区无人摆渡车、低速无人快递车等低速场景中十分常见、由于其庞大的计算开销、时延、数据存储等问题，以及无人车对实时控制、安全的高性能要求，导致其目前不适合应用在大范围面积、高速自动驾驶场景中。高速自动驾驶在地图定位方面使用的是高精度地图技术。

高精度地图面向无人驾驶环境采集生成地图数据,根据无人驾驶需求建立道路环境模型,在精确定位、基于车道横型的碰撞避让、降碍物检测和避让、智能调速、转向和引导方面都可以发挥重要作用。它实际上是融合了激光雷达点云数据、GPS信号、语义矢量地图（车道线、红绿灯、交通信号标志等）综合信息的一种定位技术。

![1.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9jN2FhN2IxY2QwNTJkNmMzMGIxNjk4YWFhYTZmZWYxOS5wbmc?x-oss-process=image/format,png)

高精度地图结构：

- 第一层是激光点云层，用来实现在线的点云匹配与定位
- 第二层是视觉地图，主要是视觉感知的一些焦点特征
- 第三层是矢量地图，其中包含的主要是一些道路的属性特征
- 第四层是GPS或者说卫星定位层
- 第五层是动态地图，用来反映动态的交通状况

#### 5.多传感器融合技术

简单地说,传感器融合就是将多个传感器获取的数据、信息集中在一起综合分析以便更加准确可靠地描述外界环境,从而提高系统决策的正确性。

**核心**：在于高精的时间以及空间的同步，时间上能够到10的负6次方，空间上能够到100m外3~5cm的误差。

**要求：**

- 硬件设备数量要足够,各种类型的传感器都配备,从而保证信息获取充分且冗余;
- 融合算法要足够优化,因为多传感器的使用会使需要处理的信息量大增,这其中甚至有相互矛盾的信息,如何保证系统快速地处理数据,过滤无用、错误信息,从而保证系统最终做出及时正确的决策十分关键。
- 目前多传感器融合的理论方法有贝叶斯准则法、卡尔曼滤波法、模糊集理论法、人工神经网络法等。

**两种实现方式：**

![2.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9kNDA0ZWU1ODMwZDEzMzVhNmZiMzg1NGNkMzYxMmMxZC5wbmc?x-oss-process=image/format,png)

**实例**：定位中的多传感器融合

![3.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC80MDk3NTA5ZWMyYTZkYWYyNzM5YjQxMmRjYzA2OTBlZi5wbmc?x-oss-process=image/format,png)

![4.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9jMzVjOGNmYTY2N2MwYWQ2M2ZjOWRmMWQ2N2NhMDQxMi5wbmc?x-oss-process=image/format,png)

可以使用粒子滤波的方法关联已知地图和激光雷达测量的过程，粒子滤波可以在10cm的精度内达到实时定位的效果，在城市的复杂环境中尤为有效。

### 三、无人驾驶的决策

#### 1.目标物体行为预测

**定义**：根据感知和定位的结果，实现目标物体（比如前方有一辆车）轨迹的预测和行为的分析

**实现：**

- 我们要实现一个动态的短时间内目标物体（前方车辆）的轨迹预测（蒙特卡洛采样、卡尔曼滤波）
- 根据目标物体一些状态或者行为的分析，实现一个中期的目标的轨迹预测
- 考虑红绿灯、标志牌等入射的一些信息，做一些规则的约束，对我们的目标物体行为预测和轨迹规划的一些曲线进行约束

#### 2.自车行为决策

**定义**：决策本车地行为（跟车还是换道）

**实现**：

- 基于规则的方法，列举有限驾驶状态，可保证行车安全

  ![7.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC85MzA0MTk0MDkyMjk4NWFmNWQ4ZTU2MWU5ZTkxMGEyOC5wbmc?x-oss-process=image/format,png)

- 基于深度学习的方法，可学习优秀驾驶员的驾驶模式（输入端是我们一些方向盘的转角，一些踏板的开度，包含传感器的一些信息，生成学习模型）

- 基于深度学习及规则约束的智能驾驶混合决策与路径规划系统

#### 3.自车路径规划

**定义**：本车决定好是换道，就需要规划出一条比较平滑的路径

**场景**：

![5.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC82Zjg2M2Q3MzdhMmQ3ZTcyNTY0YzQ5Zjk0NjhmN2I1OS5wbmc?x-oss-process=image/format,png)

因为这里是让本车在前方有车的情况下换道，故实现的是局部避障。

**实现**：附加不同的因素来生成路径。![6.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9iOGUyOWQ1MmVkNGY2OWVmM2I3ZDc5ZDM1MDM0MzM1OC5wbmc?x-oss-process=image/format,png)

#### 4.自车行为规划

定义：在规划好的路径上来实现车辆的控制加上车辆的速度。

![9.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC80OTI2YjI0MmU0NDg4YmJiN2RjODQ0NGNhMzc0MGE3Yi5qcGc?x-oss-process=image/format,png)

和普通车辆的控制并没有什么不同，两者都是基于一定的预设轨迹，考虑车辆当前姿态和此预设轨迹的误差并进行不断的跟踪反馈控制

### 四、无人驾驶的控制（以新能源车为例）

车辆基于一定的预设轨迹（路径规划），考虑车辆当前姿态和此预设轨迹的误差并进行不断的跟踪反馈控制车辆的方向盘转角、速度大小等，形成闭环。即所谓的对于车辆加减速的纵向控制和对于车辆方向盘转角的横向控制，其执行机构分别为方向盘、加速踏板和刹车踏板，对应的实现机制就是线控驱动、线控制动、线控转向。

#### 4.1线控驱动

**电子节气门**：取消了踏板和节气门之间的机械结构，而是通过加速踏板位置传感器去检测油门踏板的位移，这个位移就代表了驾驶员的驾驶意图。把该信号传递给ECU，ECU根据其他传感器反馈回来的信息进行分析和计算得到最佳的节气门开度，然后再驱动节气门控制电机，节气门位置传感器检测节气门的实际开度，再把该信号反馈给ECU去实现整个节气门开度的闭环控制。

![10.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9mYjE2NjAyMDkzNmE0MTJlMmNiMGEwMjMxNmE4OTNiMy5qcGc?x-oss-process=image/format,png)

**线控驱动实现：**

![9.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC84NGRmNGEwYjUwODA5YTA5OGEzZDJjZDY1ZmI4ZjFlOS5wbmc?x-oss-process=image/format,png)

VCU的主要功能是实现扭矩需求的计算以及实现扭矩分配。因此只需要VCU开放速度控制接囗就能实现线控驱动。

#### 4.2线控制动

**ABS：**

![153.png](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9jYzQyNGM4YmNkNmYwYjFiNWMxODJjYjRkMzkzNzFiMC5wbmc?x-oss-process=image/format,png)

- 轮速传感器：用于检测车轮的速度，这个速度信号会输入ABS ECU。
- ABS ECU：接收轮速信号及其他信号，计算车轮的滑移率、车轮的加速度、减速度等信号，判断车轮是否有抱死的趋势从而输出控制指令给液压控制单元
- ABS HCU（液压控制单元）：相当于执行器，接收电子控制单元的命令，执行压力调节的任务

**线控制动的实现（以ABS为例）**

加装一套执行机构和控制系统，控制系统可以和线控驱动的控制系统结合起来，比较目标车速和实际车速进行驱动油门踏板或者驱动制动踏板。（适用情况:ABS系统控制接口无法获得）

![12.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC8xYmI1ZDA5OGI5YmM2MTNkOGRjZDZmMzQzY2YxZTJjMS5qcGc?x-oss-process=image/format,png)

对ABS ECU进行接管控制，比如ABS ECU接收期望制动压力信号，直接驱动HCU。（适用于ABS的控制接口开放的情况。）

![13.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC8xOGM3YTVkYjUxN2M1MzU3M2VhOGFhMjczNTlkMjQyZi5qcGc?x-oss-process=image/format,png)

#### 4.3线控转向

汽车线控转向系统由方向盘总成、转向执行总成和主控制器(ECU)三个主要部分以及自动防故障系统、电源等辅助系统组成。

![11.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC9hNDI3MjVkNjBiNDA5NmVkZTMzMTAwYjgxYmY2YzU4YS5qcGc?x-oss-process=image/format,png)

- 方向盘总成包括了方向盘、方向盘转角传感器、力矩传感器、方向盘回正力矩电机；将驾驶员的转向意图通过测量方向盘转角转换成数字信号，然后传递给主控制器，同时接受主控制器送来的力矩信号从而产生方向盘回正力矩提供给驾驶员相应的路感信息。
- 主控制器会对采集的信号进行分析处理判明汽车的运动状态，然后向方向盘回正力矩电机和转向电机发送指令控制两个电机的工作，保证在各种工况下都具有理想的车辆响应，从而减轻驾驶员的负担，同时控制器还可以对驾驶员的操作指令进行判别，判断在当前状态下驾驶员操作是否合理。
- 自动防故障系统：包括一些列的监控和实施算法，能够针对不同的故障形式和等级作出相应的处理从而实现最大限度的保持汽车正常行驶。
- 电源系统：承担着控制器、两个执行马达以及其他车用电机的供电任务。其中仅仅是前轮转角执行马达的功率就有500-800W，加上汽车上的其他电子设备，电源的负担就已经想相当沉重了。所以要保证电网在大负荷下稳定工作，电源的性能就显得十分重要了。

**优点：**

- 轻易实现主动转向的功能
- 获得比EPS更快的响应速度
- 滤掉路面上的激震信号
- 消除了撞车事故中转向柱后移引起伤害驾驶员的可能性
- 去掉了转向系功能模块间的机械连接，布置方式灵活,可以获得更大的驾驶员腿部空间。

### 五、小结

![智能网联汽车——智能化.jpg](https://imgconvert.csdnimg.cn/aHR0cDovL3lhbnh1YW4ubm9zZG4uMTI3Lm5ldC8wZjFhMmMxOTY3MWRlZTQxN2JiNmU2MjkxNDg0MzgxMS5qcGc?x-oss-process=image/format,png)
 